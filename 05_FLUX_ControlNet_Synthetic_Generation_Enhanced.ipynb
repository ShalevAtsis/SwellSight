{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNT65y0Y7H-I"
   },
   "source": [
    "# SwellSight Enhanced: FLUX ControlNet Synthetic Generation\n",
    "\n",
    "**Project:** SwellSight Wave Analysis Model - Enhanced Pipeline\n",
    "**Pipeline Stage:** FLUX-based Real-to-Synthetic Image Generation\n",
    "\n",
    "## Overview\n",
    "This enhanced notebook implements the next-generation synthetic image generation using FLUX.1-dev with ControlNet-Depth integration. It replaces the previous Stable Diffusion pipeline with state-of-the-art FLUX models for superior image quality and depth conditioning.\n",
    "\n",
    "## Key Improvements\n",
    "1. **FLUX.1-dev Integration:** Advanced diffusion model for high-quality image generation\n",
    "2. **FLUX ControlNet-Depth:** Precise depth-conditioned generation\n",
    "3. **Mixed Precision Training:** Improved performance and memory efficiency\n",
    "4. **Dynamic Memory Management:** Adaptive batch sizing and GPU optimization\n",
    "5. **Quality Validation:** Comprehensive synthetic vs real data comparison\n",
    "\n",
    "## Prerequisites\n",
    "* **Enhanced Setup Completed:** Updated dependencies and configuration from notebook 01\n",
    "* **Depth Maps Available:** Depth-Anything-V2 results from notebook 03\n",
    "* **Augmentation Parameters:** Enhanced parameters from notebook 04\n",
    "* **GPU Runtime:** Requires high-memory GPU (A100 recommended for FLUX.1-dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ziwu_U7V7H-K"
   },
   "outputs": [],
   "source": [
    "# @title 1. Environment Setup & Enhanced Dependencies\n",
    "# Enhanced installation for FLUX.1-dev and advanced features\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add utils to path for shared functionality\n",
    "sys.path.append('./utils')\n",
    "\n",
    "def install_enhanced_packages():\n",
    "    \"\"\"Install enhanced packages for FLUX.1-dev support\"\"\"\n",
    "    packages = [\n",
    "        \"diffusers>=0.30.0\",  # Latest for FLUX support\n",
    "        \"transformers>=4.44.0\",  # Updated for FLUX tokenizers\n",
    "        \"accelerate>=0.33.0\",  # Enhanced acceleration\n",
    "        \"torch>=2.4.0\",  # Latest PyTorch\n",
    "        \"torchvision>=0.19.0\",\n",
    "        \"opencv-python\",\n",
    "        \"pillow>=10.0.0\",\n",
    "        \"numpy>=1.24.0\",\n",
    "        \"scipy>=1.11.0\",\n",
    "        \"scikit-image>=0.21.0\",\n",
    "        \"matplotlib>=3.7.0\",\n",
    "        \"tqdm>=4.65.0\",\n",
    "        \"psutil>=5.9.0\",  # Memory monitoring\n",
    "        \"sentencepiece>=0.1.99\",  # For FLUX tokenization\n",
    "    ]\n",
    "    \n",
    "    # Try to install xformers for memory optimization\n",
    "    xformers_packages = [\n",
    "        \"xformers>=0.0.22\",\n",
    "        \"flash-attn>=2.3.0\",  # Flash attention for FLUX\n",
    "    ]\n",
    "    \n",
    "    print(\"üì¶ Installing enhanced dependencies for FLUX.1-dev...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
    "    \n",
    "    # Try to install optional optimization packages\n",
    "    for pkg in xformers_packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "            print(f\"‚úÖ Installed {pkg}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"‚ö†Ô∏è Could not install {pkg} - continuing without\")\n",
    "    \n",
    "    print(\"‚úÖ Enhanced dependencies installed.\")\n",
    "\n",
    "# Check and install dependencies\n",
    "try:\n",
    "    import diffusers\n",
    "    from diffusers import FluxPipeline, FluxControlNetPipeline\n",
    "    print(f\"‚úÖ Diffusers version: {diffusers.__version__}\")\n",
    "except ImportError:\n",
    "    install_enhanced_packages()\n",
    "    import diffusers\n",
    "    from diffusers import FluxPipeline, FluxControlNetPipeline\n",
    "\n",
    "# Enhanced GPU detection and memory info\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"‚ùå ERROR: No GPU detected. FLUX.1-dev requires GPU acceleration.\")\n",
    "    print(\"   Please ensure you have a CUDA-compatible GPU and drivers installed.\")\n",
    "    raise RuntimeError(\"GPU required for FLUX.1-dev\")\n",
    "else:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"‚úÖ GPU Detected: {device_name}\")\n",
    "    print(f\"üìä GPU Memory: {memory_gb:.1f} GB\")\n",
    "    \n",
    "    if memory_gb < 16:\n",
    "        print(\"‚ö†Ô∏è WARNING: FLUX.1-dev works best with 16GB+ GPU memory.\")\n",
    "        print(\"   Consider using smaller batch sizes or CPU offloading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzrZ-jm97H-L"
   },
   "outputs": [],
   "source": [
    "# @title 2. Load Configuration & Shared Utilities\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "\n",
    "# Import shared utilities\n",
    "try:\n",
    "    from config_manager import ConfigManager\n",
    "    from memory_optimizer import MemoryOptimizer\n",
    "    from data_validator import DataValidator\n",
    "    from error_handler import ErrorHandler\n",
    "    from progress_tracker import ProgressTracker\n",
    "    from data_flow_manager import DataFlowManager\n",
    "    print(\"‚úÖ Shared utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import shared utilities: {e}\")\n",
    "    print(\"   Continuing with basic functionality...\")\n",
    "    # Define minimal fallback classes\n",
    "    class ConfigManager:\n",
    "        @staticmethod\n",
    "        def load_config(path='config.json'):\n",
    "            with open(path, 'r') as f:\n",
    "                return json.load(f)\n",
    "    \n",
    "    class MemoryOptimizer:\n",
    "        @staticmethod\n",
    "        def get_optimal_batch_size(available_memory, item_size_mb=100):\n",
    "            return max(1, int(available_memory * 0.8 / item_size_mb))\n",
    "        \n",
    "        @staticmethod\n",
    "        def cleanup_memory():\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    class DataValidator:\n",
    "        @staticmethod\n",
    "        def validate_image_quality(image_path):\n",
    "            return {'score': 0.8, 'valid': True}\n",
    "    \n",
    "    class ErrorHandler:\n",
    "        @staticmethod\n",
    "        def handle_gpu_memory_error(operation, fallback_func=None):\n",
    "            print(f\"‚ö†Ô∏è GPU memory error in {operation}\")\n",
    "            if fallback_func:\n",
    "                return fallback_func()\n",
    "            return None\n",
    "    \n",
    "    class ProgressTracker:\n",
    "        def __init__(self, total, description=\"Processing\"):\n",
    "            from tqdm import tqdm\n",
    "            self.pbar = tqdm(total=total, desc=description)\n",
    "        \n",
    "        def update(self, n=1):\n",
    "            self.pbar.update(n)\n",
    "        \n",
    "        def close(self):\n",
    "            self.pbar.close()\n",
    "    \n",
    "    class DataFlowManager:\n",
    "        @staticmethod\n",
    "        def load_previous_results(stage_name, required_files=None):\n",
    "            # Basic implementation\n",
    "            return {}\n",
    "        \n",
    "        @staticmethod\n",
    "        def save_stage_results(data, stage_name, metadata=None):\n",
    "            # Basic implementation\n",
    "            pass\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    config = ConfigManager.load_config('config.json')\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"üìã Pipeline: {config['pipeline']['name']} v{config['pipeline']['version']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration Error: {e}\")\n",
    "    print(\"   Using default configuration...\")\n",
    "    config = {\n",
    "        'models': {\n",
    "            'base_model': {'name': 'black-forest-labs/FLUX.1-dev'},\n",
    "            'controlnet_model': {'name': 'Shakker-Labs/FLUX.1-dev-ControlNet-Depth'},\n",
    "            'mixed_precision': True\n",
    "        },\n",
    "        'processing': {'batch_size': 'auto'},\n",
    "        'paths': {'output_dir': './outputs'}\n",
    "    }\n",
    "\n",
    "# Setup paths\n",
    "OUTPUT_DIR = Path(config['paths']['output_dir'])\n",
    "SYNTHETIC_DIR = OUTPUT_DIR / 'synthetic'\n",
    "IMAGES_DIR = SYNTHETIC_DIR / 'images'\n",
    "METADATA_DIR = SYNTHETIC_DIR / 'metadata'\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [SYNTHETIC_DIR, IMAGES_DIR, METADATA_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Output Directory: {IMAGES_DIR}\")\n",
    "print(f\"üìä Metadata Directory: {METADATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2Ns4C8X7H-M"
   },
   "outputs": [],
   "source": [
    "# @title 3. Enhanced FLUX ControlNet Generator Class\n",
    "from diffusers import FluxControlNetPipeline, FluxControlNetModel\n",
    "from diffusers.utils import load_image\n",
    "import torch.nn.functional as F\n",
    "from scipy import stats\n",
    "import psutil\n",
    "\n",
    "@dataclass\n",
    "class EnhancedGenerationResult:\n",
    "    \"\"\"Enhanced result structure with comprehensive metadata\"\"\"\n",
    "    synthetic_image: Image.Image\n",
    "    depth_map: np.ndarray\n",
    "    generation_params: Dict[str, Any]\n",
    "    quality_metrics: Dict[str, float]\n",
    "    processing_time: float\n",
    "    memory_usage: Dict[str, float]\n",
    "    model_info: Dict[str, str]\n",
    "\n",
    "class FLUXControlNetGenerator:\n",
    "    \"\"\"Enhanced FLUX.1-dev ControlNet generator with advanced features\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any], device='cuda'):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.model_config = config['models']\n",
    "        \n",
    "        # Model identifiers\n",
    "        self.base_model_id = self.model_config['base_model']['name']\n",
    "        self.controlnet_id = self.model_config['controlnet_model']['name']\n",
    "        \n",
    "        # Pipeline components\n",
    "        self.pipe = None\n",
    "        self.controlnet = None\n",
    "        \n",
    "        # Memory and performance tracking\n",
    "        self.memory_optimizer = MemoryOptimizer()\n",
    "        self.error_handler = ErrorHandler()\n",
    "        \n",
    "        # Initialize the pipeline\n",
    "        self._initialize_pipeline()\n",
    "    \n",
    "    def _initialize_pipeline(self):\n",
    "        \"\"\"Initialize FLUX ControlNet pipeline with optimizations\"\"\"\n",
    "        print(f\"üîÑ Loading FLUX ControlNet: {self.controlnet_id}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load ControlNet model\n",
    "            self.controlnet = FluxControlNetModel.from_pretrained(\n",
    "                self.controlnet_id,\n",
    "                torch_dtype=torch.float16 if self.model_config.get('mixed_precision', True) else torch.float32\n",
    "            )\n",
    "            print(\"‚úÖ FLUX ControlNet loaded\")\n",
    "            \n",
    "            # Load main pipeline\n",
    "            print(f\"üîÑ Loading FLUX.1-dev pipeline: {self.base_model_id}...\")\n",
    "            self.pipe = FluxControlNetPipeline.from_pretrained(\n",
    "                self.base_model_id,\n",
    "                controlnet=self.controlnet,\n",
    "                torch_dtype=torch.float16 if self.model_config.get('mixed_precision', True) else torch.float32\n",
    "            )\n",
    "            \n",
    "            # Apply optimizations\n",
    "            self._apply_optimizations()\n",
    "            \n",
    "            # Move to device\n",
    "            self.pipe.to(self.device)\n",
    "            print(\"‚úÖ FLUX pipeline initialized successfully\")\n",
    "            \n",
    "            # Print memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                memory_used = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üìä GPU Memory Used: {memory_used:.2f} GB\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Pipeline initialization failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _apply_optimizations(self):\n",
    "        \"\"\"Apply various optimizations to the pipeline\"\"\"\n",
    "        optimizations_applied = []\n",
    "        \n",
    "        # Enable memory efficient attention if available\n",
    "        try:\n",
    "            self.pipe.enable_xformers_memory_efficient_attention()\n",
    "            optimizations_applied.append(\"xformers\")\n",
    "        except Exception:\n",
    "            try:\n",
    "                self.pipe.enable_attention_slicing()\n",
    "                optimizations_applied.append(\"attention_slicing\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Enable model CPU offload if configured\n",
    "        if self.model_config.get('cpu_offload', False):\n",
    "            try:\n",
    "                self.pipe.enable_model_cpu_offload()\n",
    "                optimizations_applied.append(\"cpu_offload\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Enable sequential CPU offload for extreme memory saving\n",
    "        if self.model_config.get('sequential_offload', False):\n",
    "            try:\n",
    "                self.pipe.enable_sequential_cpu_offload()\n",
    "                optimizations_applied.append(\"sequential_offload\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        if optimizations_applied:\n",
    "            print(f\"üöÄ Optimizations enabled: {', '.join(optimizations_applied)}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No optimizations could be applied\")\n",
    "    \n",
    "    def preprocess_depth_map(self, depth_map: np.ndarray, target_size: Tuple[int, int] = (1024, 1024)) -> Image.Image:\n",
    "        \"\"\"Enhanced depth map preprocessing for FLUX ControlNet\"\"\"\n",
    "        # Ensure depth map is 2D\n",
    "        if len(depth_map.shape) == 3:\n",
    "            depth_map = depth_map.squeeze()\n",
    "        \n",
    "        # Normalize to 0-1 range\n",
    "        if depth_map.max() != depth_map.min():\n",
    "            depth_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "        else:\n",
    "            depth_normalized = np.zeros_like(depth_map)\n",
    "        \n",
    "        # Apply gentle smoothing to reduce noise\n",
    "        depth_smoothed = cv2.GaussianBlur(depth_normalized, (3, 3), 0.5)\n",
    "        \n",
    "        # Convert to uint8\n",
    "        depth_uint8 = (depth_smoothed * 255).astype(np.uint8)\n",
    "        \n",
    "        # Resize to target size\n",
    "        depth_resized = cv2.resize(depth_uint8, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convert to RGB PIL Image (FLUX expects RGB)\n",
    "        depth_rgb = cv2.cvtColor(depth_resized, cv2.COLOR_GRAY2RGB)\n",
    "        return Image.fromarray(depth_rgb)\n",
    "    \n",
    "    def calculate_quality_metrics(self, synthetic_image: Image.Image, depth_map: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Calculate comprehensive quality metrics for generated images\"\"\"\n",
    "        # Convert to numpy for analysis\n",
    "        img_array = np.array(synthetic_image)\n",
    "        \n",
    "        # Basic image quality metrics\n",
    "        brightness = np.mean(img_array)\n",
    "        contrast = np.std(img_array)\n",
    "        \n",
    "        # Color distribution metrics\n",
    "        color_variance = np.var(img_array, axis=(0, 1)).mean()\n",
    "        \n",
    "        # Edge preservation (compare with depth edges)\n",
    "        gray_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        img_edges = cv2.Canny(gray_img, 50, 150)\n",
    "        depth_edges = cv2.Canny((depth_map * 255).astype(np.uint8), 50, 150)\n",
    "        \n",
    "        # Edge correlation (how well synthetic edges match depth edges)\n",
    "        edge_correlation = np.corrcoef(img_edges.flatten(), depth_edges.flatten())[0, 1]\n",
    "        edge_correlation = 0.0 if np.isnan(edge_correlation) else edge_correlation\n",
    "        \n",
    "        return {\n",
    "            'brightness': float(brightness / 255.0),\n",
    "            'contrast': float(contrast / 255.0),\n",
    "            'color_variance': float(color_variance / 255.0),\n",
    "            'edge_correlation': float(edge_correlation),\n",
    "            'overall_quality': float((brightness/255 + contrast/255 + abs(edge_correlation)) / 3)\n",
    "        }\n",
    "    \n",
    "    def generate_with_memory_management(self, depth_map: np.ndarray, params: Dict[str, Any]) -> EnhancedGenerationResult:\n",
    "        \"\"\"Generate synthetic image with comprehensive memory management\"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Record initial memory state\n",
    "        initial_memory = {\n",
    "            'gpu_allocated': torch.cuda.memory_allocated() / (1024**3) if torch.cuda.is_available() else 0,\n",
    "            'gpu_reserved': torch.cuda.memory_reserved() / (1024**3) if torch.cuda.is_available() else 0,\n",
    "            'system_memory': psutil.virtual_memory().percent\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Preprocess depth map\n",
    "            target_size = (params.get('width', 1024), params.get('height', 1024))\n",
    "            depth_image = self.preprocess_depth_map(depth_map, target_size)\n",
    "            \n",
    "            # Setup generation parameters\n",
    "            generation_kwargs = {\n",
    "                'prompt': params['prompt'],\n",
    "                'control_image': depth_image,\n",
    "                'height': params.get('height', 1024),\n",
    "                'width': params.get('width', 1024),\n",
    "                'num_inference_steps': params.get('num_inference_steps', 28),\n",
    "                'guidance_scale': params.get('guidance_scale', 3.5),\n",
    "                'controlnet_conditioning_scale': params.get('controlnet_conditioning_scale', 0.6),\n",
    "            }\n",
    "            \n",
    "            # Add seed if provided\n",
    "            if 'seed' in params:\n",
    "                generator = torch.Generator(device=self.device).manual_seed(int(params['seed']))\n",
    "                generation_kwargs['generator'] = generator\n",
    "            \n",
    "            # Generate image\n",
    "            with torch.cuda.amp.autocast(enabled=self.model_config.get('mixed_precision', True)):\n",
    "                result = self.pipe(**generation_kwargs)\n",
    "            \n",
    "            synthetic_image = result.images[0]\n",
    "            \n",
    "            # Calculate quality metrics\n",
    "            quality_metrics = self.calculate_quality_metrics(synthetic_image, depth_map)\n",
    "            \n",
    "            # Record final memory state\n",
    "            final_memory = {\n",
    "                'gpu_allocated': torch.cuda.memory_allocated() / (1024**3) if torch.cuda.is_available() else 0,\n",
    "                'gpu_reserved': torch.cuda.memory_reserved() / (1024**3) if torch.cuda.is_available() else 0,\n",
    "                'system_memory': psutil.virtual_memory().percent\n",
    "            }\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            return EnhancedGenerationResult(\n",
    "                synthetic_image=synthetic_image,\n",
    "                depth_map=depth_map,\n",
    "                generation_params=params,\n",
    "                quality_metrics=quality_metrics,\n",
    "                processing_time=processing_time,\n",
    "                memory_usage={\n",
    "                    'initial': initial_memory,\n",
    "                    'final': final_memory,\n",
    "                    'peak_gpu_gb': final_memory['gpu_allocated']\n",
    "                },\n",
    "                model_info={\n",
    "                    'base_model': self.base_model_id,\n",
    "                    'controlnet': self.controlnet_id,\n",
    "                    'device': str(self.device),\n",
    "                    'mixed_precision': str(self.model_config.get('mixed_precision', True))\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            print(f\"‚ö†Ô∏è GPU Memory Error: {e}\")\n",
    "            # Attempt memory cleanup and retry with smaller parameters\n",
    "            self.memory_optimizer.cleanup_memory()\n",
    "            \n",
    "            # Reduce parameters for retry\n",
    "            params_reduced = params.copy()\n",
    "            params_reduced['height'] = min(params_reduced.get('height', 1024), 768)\n",
    "            params_reduced['width'] = min(params_reduced.get('width', 1024), 768)\n",
    "            params_reduced['num_inference_steps'] = min(params_reduced.get('num_inference_steps', 28), 20)\n",
    "            \n",
    "            print(\"üîÑ Retrying with reduced parameters...\")\n",
    "            return self.generate_with_memory_management(depth_map, params_reduced)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Generation failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        if hasattr(self, 'pipe') and self.pipe is not None:\n",
    "            del self.pipe\n",
    "        if hasattr(self, 'controlnet') and self.controlnet is not None:\n",
    "            del self.controlnet\n",
    "        self.memory_optimizer.cleanup_memory()\n",
    "        print(\"üßπ Generator resources cleaned up\")\n",
    "\n",
    "print(\"‚úÖ Enhanced FLUX ControlNet Generator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsKFKxge7H-O"
   },
   "outputs": [],
   "source": [
    "# @title 4. Initialize Enhanced FLUX Generator\n",
    "# Initialize the FLUX ControlNet generator with configuration\n",
    "\n",
    "try:\n",
    "    print(\"üöÄ Initializing Enhanced FLUX ControlNet Generator...\")\n",
    "    generator = FLUXControlNetGenerator(config, device='cuda')\n",
    "    print(\"‚úÖ FLUX Generator initialized successfully\")\n",
    "    \n",
    "    # Display model information\n",
    "    print(\"\\nüìã Model Configuration:\")\n",
    "    print(f\"   Base Model: {generator.base_model_id}\")\n",
    "    print(f\"   ControlNet: {generator.controlnet_id}\")\n",
    "    print(f\"   Mixed Precision: {generator.model_config.get('mixed_precision', True)}\")\n",
    "    print(f\"   Device: {generator.device}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize FLUX generator: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting suggestions:\")\n",
    "    print(\"   1. Ensure you have sufficient GPU memory (16GB+ recommended)\")\n",
    "    print(\"   2. Try enabling CPU offloading in config.json\")\n",
    "    print(\"   3. Reduce batch size or image resolution\")\n",
    "    print(\"   4. Check internet connection for model downloads\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2ea-BZ17H-P"
   },
   "outputs": [],
   "source": [
    "# @title 5. Load Data and Setup Dynamic Batch Processing\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "class DynamicBatchProcessor:\n",
    "    \"\"\"Dynamic batch processor with memory-aware sizing\"\"\"\n",
    "    \n",
    "    def __init__(self, generator: FLUXControlNetGenerator, config: Dict[str, Any]):\n",
    "        self.generator = generator\n",
    "        self.config = config\n",
    "        self.memory_optimizer = MemoryOptimizer()\n",
    "        self.data_validator = DataValidator()\n",
    "        \n",
    "        # Processing statistics\n",
    "        self.stats = {\n",
    "            'total_processed': 0,\n",
    "            'successful': 0,\n",
    "            'failed': 0,\n",
    "            'total_time': 0.0,\n",
    "            'quality_scores': []\n",
    "        }\n",
    "    \n",
    "    def calculate_optimal_batch_size(self) -> int:\n",
    "        \"\"\"Calculate optimal batch size based on available memory\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            # Get available GPU memory\n",
    "            total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "            allocated_memory = torch.cuda.memory_allocated()\n",
    "            available_memory = (total_memory - allocated_memory) / (1024**3)  # GB\n",
    "            \n",
    "            # Estimate memory per image (FLUX.1-dev is memory intensive)\n",
    "            memory_per_image = 2.5  # GB per 1024x1024 image\n",
    "            \n",
    "            # Calculate batch size with safety margin\n",
    "            batch_size = max(1, int(available_memory * 0.7 / memory_per_image))\n",
    "            \n",
    "            print(f\"üìä Memory Analysis:\")\n",
    "            print(f\"   Available GPU Memory: {available_memory:.1f} GB\")\n",
    "            print(f\"   Estimated per image: {memory_per_image} GB\")\n",
    "            print(f\"   Optimal batch size: {batch_size}\")\n",
    "            \n",
    "            return batch_size\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def load_depth_maps_and_params(self) -> Tuple[List[np.ndarray], List[Dict[str, Any]]]:\n",
    "        \"\"\"Load depth maps and generation parameters\"\"\"\n",
    "        print(\"üìÇ Loading depth maps and parameters...\")\n",
    "        \n",
    "        # Try to load from previous pipeline stages\n",
    "        try:\n",
    "            # Load depth extraction results\n",
    "            depth_results = DataFlowManager.load_previous_results(\n",
    "                \"depth_anything_v2_extraction\",\n",
    "                [\"depth_maps.json\", \"depth_quality.json\"]\n",
    "            )\n",
    "            \n",
    "            # Load augmentation parameters\n",
    "            augmentation_results = DataFlowManager.load_previous_results(\n",
    "                \"data_augmentation_system\",\n",
    "                [\"augmentation_params.json\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {len(depth_results.get('depth_maps', []))} depth maps\")\n",
    "            print(f\"‚úÖ Loaded {len(augmentation_results.get('generation_parameters', []))} parameter sets\")\n",
    "            \n",
    "            return depth_results.get('depth_maps', []), augmentation_results.get('generation_parameters', [])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load from previous stages: {e}\")\n",
    "            print(\"   Using fallback data loading...\")\n",
    "            \n",
    "            # Fallback: look for depth map files\n",
    "            depth_files = glob.glob(\"./data/depth_maps/*.npy\")\n",
    "            if not depth_files:\n",
    "                depth_files = glob.glob(\"./outputs/depth_maps/*.npy\")\n",
    "            \n",
    "            depth_maps = []\n",
    "            for depth_file in depth_files[:10]:  # Limit for demo\n",
    "                try:\n",
    "                    depth_map = np.load(depth_file)\n",
    "                    depth_maps.append(depth_map)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Could not load {depth_file}: {e}\")\n",
    "            \n",
    "            # Create sample parameters if none available\n",
    "            sample_params = [\n",
    "                {\n",
    "                    'prompt': 'A beautiful ocean beach scene with waves, photorealistic, high quality',\n",
    "                    'height': 1024,\n",
    "                    'width': 1024,\n",
    "                    'num_inference_steps': 28,\n",
    "                    'guidance_scale': 3.5,\n",
    "                    'controlnet_conditioning_scale': 0.6,\n",
    "                    'seed': 42 + i\n",
    "                }\n",
    "                for i in range(len(depth_maps))\n",
    "            ]\n",
    "            \n",
    "            print(f\"üìã Using {len(depth_maps)} depth maps with sample parameters\")\n",
    "            return depth_maps, sample_params\n",
    "    \n",
    "    def process_batch(self, depth_maps: List[np.ndarray], params_list: List[Dict[str, Any]], \n",
    "                     batch_size: int = None) -> List[EnhancedGenerationResult]:\n",
    "        \"\"\"Process a batch of images with dynamic sizing\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.calculate_optimal_batch_size()\n",
    "        \n",
    "        results = []\n",
    "        total_items = min(len(depth_maps), len(params_list))\n",
    "        \n",
    "        print(f\"üöÄ Starting batch processing: {total_items} items, batch size: {batch_size}\")\n",
    "        \n",
    "        # Create progress tracker\n",
    "        progress = ProgressTracker(total_items, \"Generating synthetic images\")\n",
    "        \n",
    "        try:\n",
    "            for i in range(0, total_items, batch_size):\n",
    "                batch_end = min(i + batch_size, total_items)\n",
    "                batch_depth_maps = depth_maps[i:batch_end]\n",
    "                batch_params = params_list[i:batch_end]\n",
    "                \n",
    "                print(f\"\\nüì¶ Processing batch {i//batch_size + 1}: items {i+1}-{batch_end}\")\n",
    "                \n",
    "                # Process each item in the batch\n",
    "                for j, (depth_map, params) in enumerate(zip(batch_depth_maps, batch_params)):\n",
    "                    try:\n",
    "                        # Validate depth map quality\n",
    "                        if depth_map.size == 0 or np.all(depth_map == 0):\n",
    "                            print(f\"‚ö†Ô∏è Skipping invalid depth map {i+j+1}\")\n",
    "                            self.stats['failed'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Generate synthetic image\n",
    "                        result = self.generator.generate_with_memory_management(depth_map, params)\n",
    "                        \n",
    "                        # Save result\n",
    "                        image_filename = f\"synthetic_{i+j+1:04d}.png\"\n",
    "                        image_path = IMAGES_DIR / image_filename\n",
    "                        result.synthetic_image.save(image_path, \"PNG\")\n",
    "                        \n",
    "                        # Update statistics\n",
    "                        self.stats['successful'] += 1\n",
    "                        self.stats['total_time'] += result.processing_time\n",
    "                        self.stats['quality_scores'].append(result.quality_metrics['overall_quality'])\n",
    "                        \n",
    "                        results.append(result)\n",
    "                        \n",
    "                        print(f\"‚úÖ Generated {image_filename} (Quality: {result.quality_metrics['overall_quality']:.3f})\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Failed to generate image {i+j+1}: {e}\")\n",
    "                        self.stats['failed'] += 1\n",
    "                    \n",
    "                    finally:\n",
    "                        progress.update(1)\n",
    "                        self.stats['total_processed'] += 1\n",
    "                \n",
    "                # Memory cleanup between batches\n",
    "                self.memory_optimizer.cleanup_memory()\n",
    "                \n",
    "                # Display batch statistics\n",
    "                if torch.cuda.is_available():\n",
    "                    memory_used = torch.cuda.memory_allocated() / (1024**3)\n",
    "                    print(f\"üìä Batch complete. GPU Memory: {memory_used:.2f} GB\")\n",
    "        \n",
    "        finally:\n",
    "            progress.close()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_processing_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive processing summary\"\"\"\n",
    "        avg_quality = np.mean(self.stats['quality_scores']) if self.stats['quality_scores'] else 0.0\n",
    "        avg_time = self.stats['total_time'] / max(1, self.stats['successful'])\n",
    "        \n",
    "        return {\n",
    "            'total_processed': self.stats['total_processed'],\n",
    "            'successful': self.stats['successful'],\n",
    "            'failed': self.stats['failed'],\n",
    "            'success_rate': self.stats['successful'] / max(1, self.stats['total_processed']),\n",
    "            'average_quality': avg_quality,\n",
    "            'average_processing_time': avg_time,\n",
    "            'total_processing_time': self.stats['total_time'],\n",
    "            'quality_distribution': {\n",
    "                'min': min(self.stats['quality_scores']) if self.stats['quality_scores'] else 0,\n",
    "                'max': max(self.stats['quality_scores']) if self.stats['quality_scores'] else 0,\n",
    "                'std': np.std(self.stats['quality_scores']) if self.stats['quality_scores'] else 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Initialize the batch processor\n",
    "print(\"üîß Initializing Dynamic Batch Processor...\")\n",
    "batch_processor = DynamicBatchProcessor(generator, config)\n",
    "\n",
    "# Load data\n",
    "depth_maps, generation_params = batch_processor.load_depth_maps_and_params()\n",
    "\n",
    "if not depth_maps or not generation_params:\n",
    "    print(\"‚ùå No data available for processing\")\n",
    "    print(\"   Please ensure previous pipeline stages have been completed\")\n",
    "else:\n",
    "    print(f\"‚úÖ Ready to process {len(depth_maps)} depth maps with {len(generation_params)} parameter sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_processing_cell"
   },
   "outputs": [],
   "source": [
    "# @title 6. Execute Enhanced Batch Processing\n",
    "# Run the enhanced FLUX generation with dynamic batch sizing\n",
    "\n",
    "if depth_maps and generation_params:\n",
    "    print(\"üöÄ Starting Enhanced FLUX Synthetic Generation...\")\n",
    "    print(f\"üìä Processing {len(depth_maps)} depth maps\")\n",
    "    \n",
    "    # Limit processing for demonstration (remove limit for full processing)\n",
    "    max_images = min(len(depth_maps), config.get('processing', {}).get('max_images', 50))\n",
    "    \n",
    "    try:\n",
    "        # Process the batch\n",
    "        results = batch_processor.process_batch(\n",
    "            depth_maps[:max_images], \n",
    "            generation_params[:max_images]\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n‚úÖ Batch processing completed!\")\n",
    "        print(f\"üìà Generated {len(results)} synthetic images\")\n",
    "        \n",
    "        # Get processing summary\n",
    "        summary = batch_processor.get_processing_summary()\n",
    "        \n",
    "        print(\"\\nüìä Processing Summary:\")\n",
    "        print(f\"   Total Processed: {summary['total_processed']}\")\n",
    "        print(f\"   Successful: {summary['successful']}\")\n",
    "        print(f\"   Failed: {summary['failed']}\")\n",
    "        print(f\"   Success Rate: {summary['success_rate']:.1%}\")\n",
    "        print(f\"   Average Quality: {summary['average_quality']:.3f}\")\n",
    "        print(f\"   Average Time per Image: {summary['average_processing_time']:.1f}s\")\n",
    "        print(f\"   Total Processing Time: {summary['total_processing_time']:.1f}s\")\n",
    "        \n",
    "        # Save processing results\n",
    "        results_metadata = {\n",
    "            'stage_name': 'flux_controlnet_generation',\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'model_info': {\n",
    "                'base_model': generator.base_model_id,\n",
    "                'controlnet': generator.controlnet_id,\n",
    "                'mixed_precision': generator.model_config.get('mixed_precision', True)\n",
    "            },\n",
    "            'processing_summary': summary,\n",
    "            'generated_images': [f\"synthetic_{i+1:04d}.png\" for i in range(len(results))],\n",
    "            'configuration': config\n",
    "        }\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_file = METADATA_DIR / 'flux_generation_results.json'\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(results_metadata, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\nüíæ Results saved to {IMAGES_DIR}\")\n",
    "        print(f\"üìã Metadata saved to {metadata_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Batch processing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Save partial results if any\n",
    "        summary = batch_processor.get_processing_summary()\n",
    "        if summary['successful'] > 0:\n",
    "            print(f\"\\nüíæ Saving {summary['successful']} partial results...\")\n",
    "            partial_metadata = {\n",
    "                'stage_name': 'flux_controlnet_generation_partial',\n",
    "                'timestamp': pd.Timestamp.now().isoformat(),\n",
    "                'error': str(e),\n",
    "                'processing_summary': summary\n",
    "            }\n",
    "            \n",
    "            partial_file = METADATA_DIR / 'flux_generation_partial.json'\n",
    "            with open(partial_file, 'w') as f:\n",
    "                json.dump(partial_metadata, f, indent=2, default=str)\n",
    "else:\n",
    "    print(\"‚ùå No data available for processing\")\n",
    "    print(\"   Please run previous pipeline stages first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quality_analysis_cell"
   },
   "outputs": [],
   "source": [
    "# @title 7. Quality Analysis and Data Distribution Comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as scipy_stats\n",
    "import pandas as pd\n",
    "\n",
    "class QualityAnalyzer:\n",
    "    \"\"\"Comprehensive quality analysis for synthetic vs real data\"\"\"\n",
    "    \n",
    "    def __init__(self, synthetic_results: List[EnhancedGenerationResult]):\n",
    "        self.synthetic_results = synthetic_results\n",
    "        self.analysis_results = {}\n",
    "    \n",
    "    def analyze_synthetic_quality(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze quality metrics of synthetic images\"\"\"\n",
    "        if not self.synthetic_results:\n",
    "            return {'error': 'No synthetic results available'}\n",
    "        \n",
    "        # Extract quality metrics\n",
    "        quality_data = {\n",
    "            'brightness': [r.quality_metrics['brightness'] for r in self.synthetic_results],\n",
    "            'contrast': [r.quality_metrics['contrast'] for r in self.synthetic_results],\n",
    "            'color_variance': [r.quality_metrics['color_variance'] for r in self.synthetic_results],\n",
    "            'edge_correlation': [r.quality_metrics['edge_correlation'] for r in self.synthetic_results],\n",
    "            'overall_quality': [r.quality_metrics['overall_quality'] for r in self.synthetic_results]\n",
    "        }\n",
    "        \n",
    "        # Calculate statistics\n",
    "        analysis = {}\n",
    "        for metric, values in quality_data.items():\n",
    "            analysis[metric] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values),\n",
    "                'median': np.median(values),\n",
    "                'q25': np.percentile(values, 25),\n",
    "                'q75': np.percentile(values, 75)\n",
    "            }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def compare_with_reference_data(self, reference_images_dir: str = None) -> Dict[str, Any]:\n",
    "        \"\"\"Compare synthetic data distribution with reference real data\"\"\"\n",
    "        comparison_results = {\n",
    "            'synthetic_stats': self.analyze_synthetic_quality(),\n",
    "            'comparison_available': False\n",
    "        }\n",
    "        \n",
    "        if reference_images_dir and Path(reference_images_dir).exists():\n",
    "            try:\n",
    "                # Load reference images for comparison\n",
    "                reference_files = list(Path(reference_images_dir).glob('*.jpg')) + \\\n",
    "                                list(Path(reference_images_dir).glob('*.png'))\n",
    "                \n",
    "                if reference_files:\n",
    "                    print(f\"üìä Analyzing {len(reference_files)} reference images...\")\n",
    "                    \n",
    "                    # Analyze reference images\n",
    "                    ref_metrics = []\n",
    "                    for img_path in reference_files[:20]:  # Limit for performance\n",
    "                        try:\n",
    "                            img = Image.open(img_path)\n",
    "                            img_array = np.array(img)\n",
    "                            \n",
    "                            # Calculate same metrics as synthetic\n",
    "                            brightness = np.mean(img_array) / 255.0\n",
    "                            contrast = np.std(img_array) / 255.0\n",
    "                            color_variance = np.var(img_array, axis=(0, 1)).mean() / 255.0\n",
    "                            \n",
    "                            ref_metrics.append({\n",
    "                                'brightness': brightness,\n",
    "                                'contrast': contrast,\n",
    "                                'color_variance': color_variance\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            print(f\"‚ö†Ô∏è Could not analyze {img_path}: {e}\")\n",
    "                    \n",
    "                    if ref_metrics:\n",
    "                        # Calculate reference statistics\n",
    "                        ref_stats = {}\n",
    "                        for metric in ['brightness', 'contrast', 'color_variance']:\n",
    "                            values = [m[metric] for m in ref_metrics]\n",
    "                            ref_stats[metric] = {\n",
    "                                'mean': np.mean(values),\n",
    "                                'std': np.std(values)\n",
    "                            }\n",
    "                        \n",
    "                        # Perform statistical comparison\n",
    "                        synthetic_stats = comparison_results['synthetic_stats']\n",
    "                        statistical_tests = {}\n",
    "                        \n",
    "                        for metric in ['brightness', 'contrast', 'color_variance']:\n",
    "                            if metric in synthetic_stats:\n",
    "                                # Calculate distribution similarity\n",
    "                                syn_mean = synthetic_stats[metric]['mean']\n",
    "                                ref_mean = ref_stats[metric]['mean']\n",
    "                                \n",
    "                                # Simple similarity score (1.0 = identical, 0.0 = completely different)\n",
    "                                similarity = 1.0 - min(1.0, abs(syn_mean - ref_mean) / max(syn_mean, ref_mean, 0.001))\n",
    "                                \n",
    "                                statistical_tests[metric] = {\n",
    "                                    'synthetic_mean': syn_mean,\n",
    "                                    'reference_mean': ref_mean,\n",
    "                                    'similarity_score': similarity,\n",
    "                                    'difference': abs(syn_mean - ref_mean)\n",
    "                                }\n",
    "                        \n",
    "                        comparison_results.update({\n",
    "                            'reference_stats': ref_stats,\n",
    "                            'statistical_comparison': statistical_tests,\n",
    "                            'comparison_available': True,\n",
    "                            'reference_count': len(ref_metrics)\n",
    "                        })\n",
    "                        \n",
    "                        print(\"‚úÖ Reference data comparison completed\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not perform reference comparison: {e}\")\n",
    "        \n",
    "        return comparison_results\n",
    "    \n",
    "    def generate_quality_report(self, save_path: str = None) -> str:\n",
    "        \"\"\"Generate comprehensive quality report\"\"\"\n",
    "        analysis = self.analyze_synthetic_quality()\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"# FLUX Synthetic Image Quality Report\")\n",
    "        report.append(f\"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"Total Images Analyzed: {len(self.synthetic_results)}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        report.append(\"## Quality Metrics Summary\")\n",
    "        for metric, stats in analysis.items():\n",
    "            if isinstance(stats, dict):\n",
    "                report.append(f\"### {metric.replace('_', ' ').title()}\")\n",
    "                report.append(f\"- Mean: {stats['mean']:.3f}\")\n",
    "                report.append(f\"- Std Dev: {stats['std']:.3f}\")\n",
    "                report.append(f\"- Range: {stats['min']:.3f} - {stats['max']:.3f}\")\n",
    "                report.append(f\"- Median: {stats['median']:.3f}\")\n",
    "                report.append(\"\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        if self.synthetic_results:\n",
    "            avg_time = np.mean([r.processing_time for r in self.synthetic_results])\n",
    "            total_time = sum([r.processing_time for r in self.synthetic_results])\n",
    "            \n",
    "            report.append(\"## Performance Metrics\")\n",
    "            report.append(f\"- Average Generation Time: {avg_time:.1f} seconds\")\n",
    "            report.append(f\"- Total Processing Time: {total_time:.1f} seconds\")\n",
    "            report.append(f\"- Images per Minute: {60 / avg_time:.1f}\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        # Memory usage\n",
    "        if self.synthetic_results and 'memory_usage' in self.synthetic_results[0].__dict__:\n",
    "            peak_memory = max([r.memory_usage.get('peak_gpu_gb', 0) for r in self.synthetic_results])\n",
    "            report.append(\"## Memory Usage\")\n",
    "            report.append(f\"- Peak GPU Memory: {peak_memory:.2f} GB\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        report_text = \"\\n\".join(report)\n",
    "        \n",
    "        if save_path:\n",
    "            with open(save_path, 'w') as f:\n",
    "                f.write(report_text)\n",
    "            print(f\"üìÑ Quality report saved to {save_path}\")\n",
    "        \n",
    "        return report_text\n",
    "\n",
    "# Perform quality analysis if we have results\n",
    "if 'results' in locals() and results:\n",
    "    print(\"üìä Performing Quality Analysis...\")\n",
    "    \n",
    "    analyzer = QualityAnalyzer(results)\n",
    "    \n",
    "    # Analyze synthetic quality\n",
    "    quality_analysis = analyzer.analyze_synthetic_quality()\n",
    "    \n",
    "    print(\"\\nüìà Synthetic Image Quality Analysis:\")\n",
    "    for metric, stats in quality_analysis.items():\n",
    "        if isinstance(stats, dict):\n",
    "            print(f\"   {metric.replace('_', ' ').title()}:\")\n",
    "            print(f\"     Mean: {stats['mean']:.3f} ¬± {stats['std']:.3f}\")\n",
    "            print(f\"     Range: [{stats['min']:.3f}, {stats['max']:.3f}]\")\n",
    "    \n",
    "    # Try to compare with reference data\n",
    "    reference_dirs = ['./data/real', './data/processed', './outputs/real']\n",
    "    comparison_done = False\n",
    "    \n",
    "    for ref_dir in reference_dirs:\n",
    "        if Path(ref_dir).exists():\n",
    "            print(f\"\\nüîç Comparing with reference data in {ref_dir}...\")\n",
    "            comparison = analyzer.compare_with_reference_data(ref_dir)\n",
    "            \n",
    "            if comparison['comparison_available']:\n",
    "                print(\"\\nüìä Synthetic vs Reference Comparison:\")\n",
    "                for metric, comp in comparison['statistical_comparison'].items():\n",
    "                    print(f\"   {metric.replace('_', ' ').title()}:\")\n",
    "                    print(f\"     Synthetic: {comp['synthetic_mean']:.3f}\")\n",
    "                    print(f\"     Reference: {comp['reference_mean']:.3f}\")\n",
    "                    print(f\"     Similarity: {comp['similarity_score']:.1%}\")\n",
    "                comparison_done = True\n",
    "                break\n",
    "    \n",
    "    if not comparison_done:\n",
    "        print(\"\\n‚ö†Ô∏è No reference data found for comparison\")\n",
    "        print(\"   Place real images in ./data/real/ for distribution comparison\")\n",
    "    \n",
    "    # Generate and save quality report\n",
    "    report_path = METADATA_DIR / 'quality_report.md'\n",
    "    quality_report = analyzer.generate_quality_report(str(report_path))\n",
    "    \n",
    "    print(f\"\\nüìÑ Comprehensive quality report generated: {report_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results available for quality analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_cell"
   },
   "outputs": [],
   "source": [
    "# @title 8. Cleanup and Final Summary\n",
    "import gc\n",
    "\n",
    "# Cleanup resources\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "try:\n",
    "    if 'generator' in locals():\n",
    "        generator.cleanup()\n",
    "    \n",
    "    # Clear large variables\n",
    "    if 'results' in locals():\n",
    "        del results\n",
    "    if 'depth_maps' in locals():\n",
    "        del depth_maps\n",
    "    if 'generation_params' in locals():\n",
    "        del generation_params\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        final_memory = torch.cuda.memory_allocated() / (1024**3)\n",
    "        print(f\"üìä Final GPU Memory Usage: {final_memory:.2f} GB\")\n",
    "    \n",
    "    print(\"‚úÖ Cleanup completed\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Cleanup warning: {e}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ FLUX ControlNet Synthetic Generation Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'batch_processor' in locals():\n",
    "    final_summary = batch_processor.get_processing_summary()\n",
    "    \n",
    "    print(f\"\\nüìä Final Statistics:\")\n",
    "    print(f\"   ‚úÖ Successfully Generated: {final_summary['successful']} images\")\n",
    "    print(f\"   ‚ùå Failed: {final_summary['failed']} images\")\n",
    "    print(f\"   üìà Success Rate: {final_summary['success_rate']:.1%}\")\n",
    "    print(f\"   ‚≠ê Average Quality Score: {final_summary['average_quality']:.3f}\")\n",
    "    print(f\"   ‚è±Ô∏è Total Processing Time: {final_summary['total_processing_time']:.1f} seconds\")\n",
    "\n",
    "print(f\"\\nüìÇ Output Location: {IMAGES_DIR}\")\n",
    "print(f\"üìã Metadata Location: {METADATA_DIR}\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Review generated images in the output directory\")\n",
    "print(\"   2. Check quality report for detailed analysis\")\n",
    "print(\"   3. Proceed to notebook 06 for model training\")\n",
    "print(\"   4. Use generated synthetic data for training augmentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enhanced_processing_cell"
   },
   "outputs": [],
   "source": [
    "# @title 9. Enhanced Processing with Advanced Memory Management\n",
    "# Import enhanced processing capabilities\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "try:\n",
    "    from enhanced_batch_processor import EnhancedBatchProcessor\n",
    "    from flux_memory_manager import FLUXMemoryManager, QualityValidator, DataDistributionComparator\n",
    "    print(\"‚úÖ Enhanced processing modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import enhanced modules: {e}\")\n",
    "    print(\"   Falling back to basic processing...\")\n",
    "    # Use the basic batch processor defined earlier\n",
    "    EnhancedBatchProcessor = None\n",
    "\n",
    "# Initialize enhanced processor if available\n",
    "if EnhancedBatchProcessor and 'generator' in locals():\n",
    "    print(\"üöÄ Initializing Enhanced Batch Processor...\")\n",
    "    \n",
    "    enhanced_processor = EnhancedBatchProcessor(generator, config)\n",
    "    \n",
    "    # Load reference images for distribution comparison\n",
    "    reference_images = []\n",
    "    reference_dirs = ['./data/real', './data/processed', './outputs/real']\n",
    "    \n",
    "    for ref_dir in reference_dirs:\n",
    "        ref_path = Path(ref_dir)\n",
    "        if ref_path.exists():\n",
    "            print(f\"üìÇ Loading reference images from {ref_dir}...\")\n",
    "            \n",
    "            # Load reference images\n",
    "            for img_file in list(ref_path.glob('*.jpg'))[:10] + list(ref_path.glob('*.png'))[:10]:\n",
    "                try:\n",
    "                    img = Image.open(img_file)\n",
    "                    # Resize to standard size for comparison\n",
    "                    img = img.resize((512, 512), Image.Resampling.LANCZOS)\n",
    "                    reference_images.append(img)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Could not load {img_file}: {e}\")\n",
    "            \n",
    "            if reference_images:\n",
    "                print(f\"‚úÖ Loaded {len(reference_images)} reference images\")\n",
    "                break\n",
    "    \n",
    "    if not reference_images:\n",
    "        print(\"‚ö†Ô∏è No reference images found - distribution comparison will be skipped\")\n",
    "        print(\"   Place real images in ./data/real/ for comparison\")\n",
    "    \n",
    "    # Run enhanced processing if data is available\n",
    "    if 'depth_maps' in locals() and 'generation_params' in locals() and depth_maps:\n",
    "        print(\"\\nüöÄ Starting Enhanced FLUX Processing with Quality Validation...\")\n",
    "        \n",
    "        # Limit processing for demonstration\n",
    "        max_images = min(len(depth_maps), config.get('processing', {}).get('max_images', 20))\n",
    "        \n",
    "        try:\n",
    "            # Run enhanced batch processing\n",
    "            enhanced_result = enhanced_processor.process_batch_with_quality_validation(\n",
    "                depth_maps[:max_images],\n",
    "                generation_params[:max_images],\n",
    "                IMAGES_DIR,\n",
    "                reference_images if reference_images else None\n",
    "            )\n",
    "            \n",
    "            print(\"\\n‚úÖ Enhanced Processing Completed!\")\n",
    "            print(f\"üìä Results Summary:\")\n",
    "            print(f\"   Total Processed: {enhanced_result.total_processed}\")\n",
    "            print(f\"   Successful: {enhanced_result.successful}\")\n",
    "            print(f\"   Failed: {enhanced_result.failed}\")\n",
    "            print(f\"   Success Rate: {enhanced_result.success_rate:.1%}\")\n",
    "            print(f\"   Average Quality: {enhanced_result.quality_summary['mean_quality']:.3f}\")\n",
    "            print(f\"   Peak GPU Memory: {enhanced_result.memory_usage['peak_gpu_usage']:.2f} GB\")\n",
    "            \n",
    "            if enhanced_result.distribution_comparison:\n",
    "                comp = enhanced_result.distribution_comparison\n",
    "                print(f\"   Distribution Similarity: {comp['overall_similarity']:.1%}\")\n",
    "                print(f\"   Assessment: {comp['assessment']['level'].title()}\")\n",
    "            \n",
    "            # Generate comprehensive report\n",
    "            report = enhanced_processor.generate_processing_report(enhanced_result, IMAGES_DIR)\n",
    "            print(f\"\\nüìÑ Comprehensive report generated: {IMAGES_DIR}/processing_report.md\")\n",
    "            \n",
    "            # Display quality distribution\n",
    "            if enhanced_result.quality_summary['mean_quality'] > 0:\n",
    "                quality_assessment = \"Excellent\" if enhanced_result.quality_summary['mean_quality'] >= 0.8 else \\\n",
    "                                   \"Good\" if enhanced_result.quality_summary['mean_quality'] >= 0.6 else \\\n",
    "                                   \"Acceptable\" if enhanced_result.quality_summary['mean_quality'] >= 0.4 else \"Poor\"\n",
    "                \n",
    "                print(f\"\\n‚≠ê Overall Quality Assessment: {quality_assessment}\")\n",
    "                print(f\"   Quality Range: [{enhanced_result.quality_summary['min_quality']:.3f}, {enhanced_result.quality_summary['max_quality']:.3f}]\")\n",
    "                print(f\"   Acceptable Images: {enhanced_result.quality_summary['acceptable_count']}/{enhanced_result.successful}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Enhanced processing failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # Fall back to basic processing\n",
    "            print(\"\\nüîÑ Falling back to basic processing...\")\n",
    "            if 'batch_processor' in locals():\n",
    "                basic_results = batch_processor.process_batch(\n",
    "                    depth_maps[:max_images], \n",
    "                    generation_params[:max_images]\n",
    "                )\n",
    "                print(f\"‚úÖ Basic processing completed: {len(basic_results)} images generated\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No data available for enhanced processing\")\n",
    "        print(\"   Please ensure previous pipeline stages have been completed\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Enhanced processing not available - using basic processing\")\n",
    "    # Use basic processing if enhanced is not available\n",
    "    if 'batch_processor' in locals() and 'depth_maps' in locals():\n",
    "        max_images = min(len(depth_maps), 10)\n",
    "        basic_results = batch_processor.process_batch(\n",
    "            depth_maps[:max_images], \n",
    "            generation_params[:max_images]\n",
    "        )\n",
    "        print(f\"‚úÖ Basic processing completed: {len(basic_results)} images generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validation_analysis_cell"
   },
   "outputs": [],
   "source": [
    "# @title 10. Advanced Quality Validation and Analysis\n",
    "# Perform detailed quality analysis on generated images\n",
    "\n",
    "if 'enhanced_result' in locals() and enhanced_result.successful > 0:\n",
    "    print(\"üìä Performing Advanced Quality Analysis...\")\n",
    "    \n",
    "    # Load generated images for detailed analysis\n",
    "    generated_images = []\n",
    "    quality_scores = []\n",
    "    \n",
    "    for filename in enhanced_result.generated_files[:10]:  # Analyze first 10 for performance\n",
    "        try:\n",
    "            img_path = IMAGES_DIR / filename\n",
    "            if img_path.exists():\n",
    "                img = Image.open(img_path)\n",
    "                generated_images.append(img)\n",
    "                \n",
    "                # Load corresponding metadata\n",
    "                metadata_file = IMAGES_DIR / \"metadata\" / f\"{filename.replace('.png', '_metadata.json')}\"\n",
    "                if metadata_file.exists():\n",
    "                    with open(metadata_file, 'r') as f:\n",
    "                        metadata = json.load(f)\n",
    "                        quality_scores.append(metadata.get('quality_metrics', {}).get('overall_score', 0.0))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not analyze {filename}: {e}\")\n",
    "    \n",
    "    if generated_images:\n",
    "        print(f\"\\nüìà Detailed Analysis of {len(generated_images)} Generated Images:\")\n",
    "        \n",
    "        # Quality distribution analysis\n",
    "        if quality_scores:\n",
    "            quality_array = np.array(quality_scores)\n",
    "            \n",
    "            print(f\"\\nüéØ Quality Score Distribution:\")\n",
    "            print(f\"   Mean: {np.mean(quality_array):.3f} ¬± {np.std(quality_array):.3f}\")\n",
    "            print(f\"   Median: {np.median(quality_array):.3f}\")\n",
    "            print(f\"   Range: [{np.min(quality_array):.3f}, {np.max(quality_array):.3f}]\")\n",
    "            \n",
    "            # Quality categories\n",
    "            excellent = np.sum(quality_array >= 0.8)\n",
    "            good = np.sum((quality_array >= 0.6) & (quality_array < 0.8))\n",
    "            acceptable = np.sum((quality_array >= 0.4) & (quality_array < 0.6))\n",
    "            poor = np.sum(quality_array < 0.4)\n",
    "            \n",
    "            print(f\"\\nüìä Quality Categories:\")\n",
    "            print(f\"   Excellent (‚â•0.8): {excellent} ({excellent/len(quality_scores)*100:.1f}%)\")\n",
    "            print(f\"   Good (0.6-0.8): {good} ({good/len(quality_scores)*100:.1f}%)\")\n",
    "            print(f\"   Acceptable (0.4-0.6): {acceptable} ({acceptable/len(quality_scores)*100:.1f}%)\")\n",
    "            print(f\"   Poor (<0.4): {poor} ({poor/len(quality_scores)*100:.1f}%)\")\n",
    "        \n",
    "        # Memory efficiency analysis\n",
    "        if 'enhanced_result' in locals():\n",
    "            memory_usage = enhanced_result.memory_usage\n",
    "            processing_time = enhanced_result.processing_time\n",
    "            \n",
    "            print(f\"\\n‚ö° Performance Metrics:\")\n",
    "            print(f\"   Images per Second: {enhanced_result.successful / processing_time:.2f}\")\n",
    "            print(f\"   Average Memory per Image: {memory_usage['average_gpu_usage']:.2f} GB\")\n",
    "            print(f\"   Memory Efficiency: {enhanced_result.successful / memory_usage['peak_gpu_usage']:.1f} images/GB\")\n",
    "        \n",
    "        # Distribution comparison summary\n",
    "        if enhanced_result.distribution_comparison:\n",
    "            comp = enhanced_result.distribution_comparison\n",
    "            \n",
    "            print(f\"\\nüîç Synthetic vs Real Data Comparison:\")\n",
    "            print(f\"   Overall Similarity: {comp['overall_similarity']:.1%}\")\n",
    "            print(f\"   Assessment: {comp['assessment']['message']}\")\n",
    "            \n",
    "            # Feature-specific similarities\n",
    "            print(f\"\\nüìã Feature Similarities:\")\n",
    "            for feature, comparison in comp['feature_comparisons'].items():\n",
    "                similarity = comparison['similarity_score']\n",
    "                status = \"‚úÖ\" if similarity >= 0.7 else \"‚ö†Ô∏è\" if similarity >= 0.5 else \"‚ùå\"\n",
    "                print(f\"   {status} {feature.replace('_', ' ').title()}: {similarity:.1%}\")\n",
    "        \n",
    "        # Recommendations based on analysis\n",
    "        print(f\"\\nüí° Recommendations:\")\n",
    "        \n",
    "        if quality_scores:\n",
    "            avg_quality = np.mean(quality_array)\n",
    "            if avg_quality >= 0.8:\n",
    "                print(f\"   ‚úÖ Excellent quality achieved - current settings are optimal\")\n",
    "            elif avg_quality >= 0.6:\n",
    "                print(f\"   üìà Good quality - consider fine-tuning generation parameters\")\n",
    "            elif avg_quality >= 0.4:\n",
    "                print(f\"   ‚ö†Ô∏è Acceptable quality - review depth map quality and prompts\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Poor quality - check input data and model configuration\")\n",
    "        \n",
    "        if enhanced_result.distribution_comparison:\n",
    "            similarity = enhanced_result.distribution_comparison['overall_similarity']\n",
    "            if similarity >= 0.8:\n",
    "                print(f\"   ‚úÖ Excellent distribution match - synthetic data is highly realistic\")\n",
    "            elif similarity >= 0.6:\n",
    "                print(f\"   üìä Good distribution match - minor adjustments may improve realism\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Distribution mismatch - review generation parameters and prompts\")\n",
    "        \n",
    "        # Memory optimization recommendations\n",
    "        if memory_usage['peak_gpu_usage'] > 12:\n",
    "            print(f\"   üß† High memory usage detected - consider enabling CPU offloading\")\n",
    "        elif memory_usage['peak_gpu_usage'] < 6:\n",
    "            print(f\"   üöÄ Low memory usage - can increase batch size for better efficiency\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No generated images found for analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No enhanced results available for analysis\")\n",
    "    print(\"   Run the enhanced processing cell first\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}