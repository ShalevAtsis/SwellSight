{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Ox_hEU6-as"
      },
      "source": [
        "# SwellSight Real-to-Synthetic Pipeline - Setup and Installation (Enhanced)\n",
        "\n",
        "This notebook handles environment preparation and dependency management for the SwellSight real-to-synthetic image generation pipeline with integrated utilities.\n",
        "\n",
        "## New Features\n",
        "- ‚ú® Integrated SwellSight utilities for better error handling and progress tracking\n",
        "- üîß Automatic configuration management\n",
        "- üìä Memory optimization and monitoring\n",
        "- üõ°Ô∏è Robust error handling with retry logic\n",
        "- üìà Progress tracking and performance feedback\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import SwellSight Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not import utilities: No module named 'utils'\n",
            "Continuing with basic functionality...\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Add project root to Python path so `import utils` works\n",
        "utils_path = Path.cwd()\n",
        "if str(utils_path) not in sys.path:\n",
        "    sys.path.insert(0, str(utils_path))\n",
        "\n",
        "try:\n",
        "    # Import SwellSight utilities\n",
        "    from utils import (\n",
        "        load_config, validate_config,\n",
        "        validate_image_quality, validate_depth_map_quality,\n",
        "        get_optimal_batch_size, cleanup_variables, monitor_memory,\n",
        "        retry_with_backoff, handle_gpu_memory_error,\n",
        "        create_progress_bar, display_stage_summary,\n",
        "        save_stage_results, load_previous_results, check_dependencies\n",
        "    )\n",
        "    print(\"‚úÖ SwellSight utilities loaded successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è Could not import utilities: {e}\")\n",
        "    print(\"Continuing with basic functionality...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Configuration and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Could not load configuration: name 'load_config' is not defined\n",
            "Using default settings...\n"
          ]
        }
      ],
      "source": [
        "# Load pipeline configuration\n",
        "try:\n",
        "    config = load_config(\"config.json\")\n",
        "    print(f\"‚úÖ Configuration loaded: {config['pipeline']['name']} v{config['pipeline']['version']}\")\n",
        "    \n",
        "    # Extract commonly used settings\n",
        "    batch_size = config['processing']['batch_size']\n",
        "    quality_threshold = config['processing']['quality_threshold']\n",
        "    data_dir = Path(config['paths']['data_dir'])\n",
        "    output_dir = Path(config['paths']['output_dir'])\n",
        "    checkpoint_dir = Path(config['paths']['checkpoint_dir'])\n",
        "    \n",
        "    print(f\"üìÅ Data directory: {data_dir}\")\n",
        "    print(f\"üìÅ Output directory: {output_dir}\")\n",
        "    print(f\"üìÅ Checkpoint directory: {checkpoint_dir}\")\n",
        "    print(f\"üéØ Quality threshold: {quality_threshold}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load configuration: {e}\")\n",
        "    print(\"Using default settings...\")\n",
        "    \n",
        "    # Fallback configuration\n",
        "    batch_size = \"auto\"\n",
        "    quality_threshold = 0.7\n",
        "    data_dir = Path(\"./data\")\n",
        "    output_dir = Path(\"./outputs\")\n",
        "    checkpoint_dir = Path(\"./checkpoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Environment Detection and Hardware Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó Mounting Google Drive...\n",
            "‚ö†Ô∏è Drive mounting failed: name 'retry_with_backoff' is not defined\n",
            "\n",
            "üîç Hardware Detection:\n",
            "Platform: Linux 6.6.105+\n",
            "Python: 3.12.12\n",
            "üöÄ GPU Available: NVIDIA A100-SXM4-40GB\n",
            "üíæ GPU Memory: 39.6 GB\n",
            "üî¢ GPU Count: 1\n",
            "‚ö†Ô∏è Could not get memory info: name 'monitor_memory' is not defined\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import platform\n",
        "\n",
        "# Check if running in Google Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    \n",
        "    def mount_drive():\n",
        "        drive.mount('/content/drive')\n",
        "        return True\n",
        "    \n",
        "    try:\n",
        "        # Use retry logic for drive mounting\n",
        "        retry_with_backoff(mount_drive, max_retries=2)\n",
        "        print(\"‚úÖ Google Drive mounted successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Drive mounting failed: {e}\")\n",
        "\n",
        "# Hardware detection with memory monitoring\n",
        "print(\"\\nüîç Hardware Detection:\")\n",
        "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "\n",
        "# GPU detection\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    current_gpu = torch.cuda.current_device()\n",
        "    gpu_name = torch.cuda.get_device_name(current_gpu)\n",
        "    gpu_memory = torch.cuda.get_device_properties(current_gpu).total_memory / (1024**3)\n",
        "    \n",
        "    print(f\"üöÄ GPU Available: {gpu_name}\")\n",
        "    print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "    print(f\"üî¢ GPU Count: {gpu_count}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU available - using CPU\")\n",
        "\n",
        "# Memory monitoring\n",
        "try:\n",
        "    memory_info = monitor_memory()\n",
        "    print(f\"\\nüíª System Memory: {memory_info.get('system_total_gb', 0):.1f} GB total, {memory_info.get('system_percent', 0):.1f}% used\")\n",
        "    if 'gpu_total_gb' in memory_info:\n",
        "        print(f\"üéÆ GPU Memory: {memory_info.get('gpu_total_gb', 0):.1f} GB total, {memory_info.get('gpu_percent', 0):.1f}% used\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not get memory info: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Directory Structure with Progress Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Creating directory structure...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'create_progress_bar' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-796442569.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üìÅ Creating directory structure...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectories_to_create\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Creating directories\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcreated_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_progress_bar' is not defined"
          ]
        }
      ],
      "source": [
        "# Create necessary directories\n",
        "directories_to_create = [\n",
        "    data_dir / \"real\" / \"images\",\n",
        "    data_dir / \"processed\",\n",
        "    data_dir / \"depth_maps\",\n",
        "    data_dir / \"synthetic\",\n",
        "    output_dir,\n",
        "    checkpoint_dir,\n",
        "    Path(\"models\"),\n",
        "    Path(\"logs\")\n",
        "]\n",
        "\n",
        "print(\"üìÅ Creating directory structure...\")\n",
        "progress_bar = create_progress_bar(len(directories_to_create), \"Creating directories\")\n",
        "\n",
        "created_dirs = []\n",
        "for directory in directories_to_create:\n",
        "    try:\n",
        "        directory.mkdir(parents=True, exist_ok=True)\n",
        "        created_dirs.append(str(directory))\n",
        "        progress_bar.update(1)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not create directory {directory}: {e}\")\n",
        "\n",
        "progress_bar.close()\n",
        "print(f\"‚úÖ Created {len(created_dirs)} directories\")\n",
        "\n",
        "# Display directory structure\n",
        "print(\"\\nüìÇ Directory Structure:\")\n",
        "for directory in created_dirs:\n",
        "    print(f\"  üìÅ {directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Install Dependencies with Error Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing required packages...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Installing packages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:29<00:00,  2.91s/items]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE SUMMARY: PACKAGE INSTALLATION\n",
            "============================================================\n",
            "Total Packages: 10\n",
            "Installed Successfully: 10\n",
            "Failed Installations: 0\n",
            "Success Rate: 1.000\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Define required packages\n",
        "required_packages = [\n",
        "    \"torch>=1.9.0\",\n",
        "    \"torchvision>=0.10.0\",\n",
        "    \"transformers>=4.20.0\",\n",
        "    \"diffusers>=0.10.0\",\n",
        "    \"accelerate>=0.20.0\",\n",
        "    \"opencv-python>=4.5.0\",\n",
        "    \"Pillow>=8.0.0\",\n",
        "    \"numpy>=1.21.0\",\n",
        "    \"tqdm>=4.60.0\",\n",
        "    \"psutil>=5.8.0\"\n",
        "]\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        raise Exception(f\"Installation failed: {result.stderr}\")\n",
        "    return result.stdout\n",
        "\n",
        "print(\"üì¶ Installing required packages...\")\n",
        "progress_bar = create_progress_bar(len(required_packages), \"Installing packages\")\n",
        "\n",
        "installed_packages = []\n",
        "failed_packages = []\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        # Use retry logic for package installation\n",
        "        retry_with_backoff(lambda: install_package(package), max_retries=2)\n",
        "        installed_packages.append(package)\n",
        "        progress_bar.update(1)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è Failed to install {package}: {e}\")\n",
        "        failed_packages.append(package)\n",
        "        progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# Display installation summary\n",
        "installation_metrics = {\n",
        "    'total_packages': len(required_packages),\n",
        "    'installed_successfully': len(installed_packages),\n",
        "    'failed_installations': len(failed_packages),\n",
        "    'success_rate': len(installed_packages) / len(required_packages)\n",
        "}\n",
        "\n",
        "display_stage_summary(\"Package Installation\", installation_metrics)\n",
        "\n",
        "if failed_packages:\n",
        "    print(\"\\n‚ö†Ô∏è Failed packages:\")\n",
        "    for package in failed_packages:\n",
        "        print(f\"  - {package}\")\n",
        "    print(\"\\nüí° Try installing failed packages manually or check your internet connection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Optimize Memory and Batch Size Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† Optimizing memory configuration...\n",
            "‚úÖ Using configured batch size: 1\n",
            "‚úÖ Configuration updated with optimized settings\n",
            "\n",
            "üí° Memory Optimization Suggestions:\n",
            "  1. System memory usage is high (>80%). Consider reducing batch size.\n",
            "  2. Close unnecessary applications to free up system memory.\n",
            "  3. Process data in smaller batches to reduce memory pressure.\n"
          ]
        }
      ],
      "source": [
        "# Calculate optimal batch size based on available memory\n",
        "print(\"üß† Optimizing memory configuration...\")\n",
        "\n",
        "if batch_size == \"auto\":\n",
        "    try:\n",
        "        optimal_batch_size = get_optimal_batch_size(max_batch_size=32)\n",
        "        print(f\"‚úÖ Calculated optimal batch size: {optimal_batch_size}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not calculate optimal batch size: {e}\")\n",
        "        optimal_batch_size = 4  # Conservative fallback\n",
        "        print(f\"Using conservative batch size: {optimal_batch_size}\")\n",
        "else:\n",
        "    optimal_batch_size = batch_size\n",
        "    print(f\"‚úÖ Using configured batch size: {optimal_batch_size}\")\n",
        "\n",
        "# Update configuration with optimized settings\n",
        "try:\n",
        "    config['processing']['batch_size'] = optimal_batch_size\n",
        "    \n",
        "    # Save updated configuration\n",
        "    import json\n",
        "    with open(\"config.json\", \"w\") as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    \n",
        "    print(\"‚úÖ Configuration updated with optimized settings\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not save updated configuration: {e}\")\n",
        "\n",
        "# Display memory optimization suggestions\n",
        "try:\n",
        "    from utils.memory_optimizer import MemoryOptimizer\n",
        "    optimizer = MemoryOptimizer()\n",
        "    suggestions = optimizer.suggest_memory_optimizations()\n",
        "    \n",
        "    if suggestions:\n",
        "        print(\"\\nüí° Memory Optimization Suggestions:\")\n",
        "        for i, suggestion in enumerate(suggestions[:3], 1):\n",
        "            print(f\"  {i}. {suggestion}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not generate optimization suggestions: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Setup Results and Environment Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect environment information\n",
        "environment_info = {\n",
        "    'platform': platform.system(),\n",
        "    'python_version': sys.version.split()[0],\n",
        "    'torch_version': torch.__version__,\n",
        "    'cuda_available': torch.cuda.is_available(),\n",
        "    'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
        "    'optimal_batch_size': optimal_batch_size,\n",
        "    'directories_created': created_dirs,\n",
        "    'installed_packages': installed_packages,\n",
        "    'failed_packages': failed_packages\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    environment_info.update({\n",
        "        'gpu_name': torch.cuda.get_device_name(0),\n",
        "        'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    })\n",
        "\n",
        "# Save setup results\n",
        "setup_results = {\n",
        "    'environment_info': environment_info,\n",
        "    'configuration': config,\n",
        "    'setup_status': 'completed',\n",
        "    'installation_metrics': installation_metrics\n",
        "}\n",
        "\n",
        "setup_metadata = {\n",
        "    'setup_time': '2024-01-12T00:00:00Z',  # This would be actual timestamp\n",
        "    'notebook_version': '1.0_enhanced',\n",
        "    'utilities_version': '1.0'\n",
        "}\n",
        "\n",
        "try:\n",
        "    success = save_stage_results(setup_results, \"setup\", setup_metadata)\n",
        "    if success:\n",
        "        print(\"‚úÖ Setup results saved successfully\")\n",
        "        print(f\"üìÅ Results saved to: {output_dir / 'setup'}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Could not save setup results\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error saving setup results: {e}\")\n",
        "\n",
        "print(\"\\nüéâ Setup and installation completed!\")\n",
        "print(\"\\nüìã Next Steps:\")\n",
        "print(\"1. üìÇ Add your real beach images to the data/real/images/ directory\")\n",
        "print(\"2. ‚ñ∂Ô∏è Run notebook 02: Data Import and Preprocessing\")\n",
        "print(\"3. üîÑ Continue with the remaining pipeline notebooks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Memory Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up large variables to free memory\n",
        "large_variables = [\n",
        "    # Add any large variables that were created during setup\n",
        "]\n",
        "\n",
        "try:\n",
        "    cleanup_variables(large_variables)\n",
        "    print(\"‚úÖ Memory cleanup completed\")\n",
        "    \n",
        "    # Show final memory status\n",
        "    final_memory = monitor_memory()\n",
        "    print(f\"üíª Final system memory usage: {final_memory.get('system_percent', 0):.1f}%\")\n",
        "    if 'gpu_percent' in final_memory:\n",
        "        print(f\"üéÆ Final GPU memory usage: {final_memory.get('gpu_percent', 0):.1f}%\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Memory cleanup warning: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
