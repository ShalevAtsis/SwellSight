{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Ox_hEU6-as"
      },
      "source": [
        "# SwellSight Real-to-Synthetic Pipeline - Setup and Installation\n",
        "\n",
        "This notebook handles environment preparation and dependency management for the SwellSight real-to-synthetic image generation pipeline.\n",
        "\n",
        "## Overview\n",
        "Based on the `real_to_synthetic_pipeline.py` script, this notebook provides:\n",
        "- Environment detection and GPU configuration\n",
        "- Installation of MiDaS depth estimation dependencies\n",
        "- ControlNet and diffusion model setup\n",
        "- SwellSight package installation and configuration\n",
        "- Directory structure creation for pipeline data\n",
        "- Configuration management for reproducible results\n",
        "\n",
        "## Pipeline Components\n",
        "1. **MiDaS Depth Extraction**: Extract depth maps from real beach images\n",
        "2. **Data Augmentation**: Generate parameter variations for synthetic diversity\n",
        "3. **ControlNet Generation**: Create synthetic images using depth conditioning\n",
        "\n",
        "## Prerequisites\n",
        "- Python 3.8+ environment\n",
        "- CUDA-capable GPU (recommended for performance)\n",
        "- At least 8GB GPU memory for ControlNet models\n",
        "- Real beach images in `data/real/images/` directory\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk1YkTg-6-a4"
      },
      "source": [
        "## 1. Environment Detection and Path Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upIUlafegSyb",
        "outputId": "fc6a7bbc-b861-470e-ecce-9d920f222119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úì Google Drive mounted successfully\n",
            "‚úì Project directory found: /content/drive/MyDrive/SwellSight\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Google Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "\n",
        "    try:\n",
        "        # Attempt 1: Standard mount\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"‚úì Google Drive mounted successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Standard mount failed: {e}\")\n",
        "\n",
        "        # Attempt 2: Force remount with extended timeout (robust fallback)\n",
        "        print(\"Trying force remount with extended timeout...\")\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "            print(\"‚úì Force remount successful\")\n",
        "        except Exception as e2:\n",
        "            print(f\"‚ùå Critical failure mounting drive: {e2}\")\n",
        "            raise\n",
        "\n",
        "    # Verify the specific project path exists\n",
        "    # Adjust this path if your folder structure changes\n",
        "    PROJECT_PATH = Path('/content/drive/MyDrive/SwellSight')\n",
        "    if PROJECT_PATH.exists():\n",
        "        print(f\"‚úì Project directory found: {PROJECT_PATH}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Project directory not found at: {PROJECT_PATH}\")\n",
        "else:\n",
        "    print(\"Not running in Google Colab. Skipping Drive mount.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V1YkTg-6-a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db45d350-e713-4fce-bba2-56c42f07a3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment Detection:\n",
            "  Google Colab: True\n",
            "  Kaggle: False\n",
            "  Local Jupyter: False\n",
            "  Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "  Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "\n",
            "Path Configuration:\n",
            "  Base path: /content\n",
            "  Drive path: /content/drive/MyDrive/SwellSight\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import platform\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import json\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "# Detect environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "IS_KAGGLE = 'kaggle_secrets' in sys.modules\n",
        "IS_LOCAL = not (IN_COLAB or IS_KAGGLE)\n",
        "\n",
        "print(f\"Environment Detection:\")\n",
        "print(f\"  Google Colab: {IN_COLAB}\")\n",
        "print(f\"  Kaggle: {IS_KAGGLE}\")\n",
        "print(f\"  Local Jupyter: {IS_LOCAL}\")\n",
        "print(f\"  Python version: {sys.version}\")\n",
        "print(f\"  Platform: {platform.platform()}\")\n",
        "\n",
        "# Set base paths based on environment\n",
        "if IN_COLAB:\n",
        "    BASE_PATH = Path('/content')\n",
        "    DRIVE_PATH = Path('/content/drive/MyDrive/SwellSight')\n",
        "elif IS_KAGGLE:\n",
        "    BASE_PATH = Path('/kaggle/working')\n",
        "    DRIVE_PATH = Path('/kaggle/working/SwellSight')\n",
        "else:\n",
        "    BASE_PATH = Path.cwd()\n",
        "    DRIVE_PATH = BASE_PATH / 'SwellSight'\n",
        "\n",
        "print(f\"\\nPath Configuration:\")\n",
        "print(f\"  Base path: {BASE_PATH}\")\n",
        "print(f\"  Drive path: {DRIVE_PATH}\")\n",
        "\n",
        "# Configure logging for pipeline\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkdZacg-6-a5"
      },
      "source": [
        "## 2. GPU Detection and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B6b93lgT6-a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8125936-c42f-435a-a111-b2b50f0f5f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Configuration:\n",
            "  CUDA available: True\n",
            "  GPU count: 1\n",
            "  GPU 0: Tesla T4 (14.7 GB)\n",
            "\n",
            "Using device: cuda:0\n",
            "GPU cache cleared\n",
            "‚úÖ Excellent: Sufficient memory for full pipeline with large models.\n"
          ]
        }
      ],
      "source": [
        "# GPU Detection\n",
        "try:\n",
        "    import torch\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "\n",
        "    print(f\"GPU Configuration:\")\n",
        "    print(f\"  CUDA available: {gpu_available}\")\n",
        "    print(f\"  GPU count: {gpu_count}\")\n",
        "\n",
        "    if gpu_available:\n",
        "        for i in range(gpu_count):\n",
        "            gpu_name = torch.cuda.get_device_name(i)\n",
        "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
        "            print(f\"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "\n",
        "        # Set default device\n",
        "        device = torch.device('cuda:0')\n",
        "        print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "        # Clear GPU cache\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU cache cleared\")\n",
        "\n",
        "        # Memory recommendations\n",
        "        current_gpu = torch.cuda.current_device()\n",
        "        gpu_memory = torch.cuda.get_device_properties(current_gpu).total_memory / 1e9\n",
        "\n",
        "        if gpu_memory < 6:\n",
        "            print(\"‚ö†Ô∏è  Warning: Less than 6GB GPU memory. Consider using smaller models.\")\n",
        "        elif gpu_memory >= 12:\n",
        "            print(\"‚úÖ Excellent: Sufficient memory for full pipeline with large models.\")\n",
        "        else:\n",
        "            print(\"‚úÖ Good: Sufficient memory for pipeline with standard models.\")\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print(f\"\\nUsing device: {device} (GPU not available)\")\n",
        "        print(\"‚ö†Ô∏è  No GPU detected. Pipeline will run on CPU (much slower).\")\n",
        "\n",
        "    # Store device for later use\n",
        "    DEVICE = device\n",
        "\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed yet - will check GPU after installation.\")\n",
        "    gpu_available = False\n",
        "    gpu_count = 0\n",
        "    DEVICE = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSgUgxYG6-a7"
      },
      "source": [
        "## 3. Google Drive Mounting (Colab Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kq_SM5Oi6-a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962ab8ea-9833-4723-dd4a-5b955005b43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úì Standard mount successful\n",
            "‚úì Google Drive mounted successfully\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    import time\n",
        "\n",
        "    print(\"Mounting Google Drive...\")\n",
        "\n",
        "    # Try multiple mount strategies\n",
        "    mount_success = False\n",
        "\n",
        "    # Strategy 1: Standard mount\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        mount_success = True\n",
        "        print(\"‚úì Standard mount successful\")\n",
        "    except Exception as e:\n",
        "        print(f\"Standard mount failed: {e}\")\n",
        "\n",
        "        # Strategy 2: Force remount with extended timeout\n",
        "        try:\n",
        "            print(\"Trying force remount with extended timeout...\")\n",
        "            drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
        "            mount_success = True\n",
        "            print(\"‚úì Force remount successful\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Force remount failed: {e2}\")\n",
        "\n",
        "            # Strategy 3: Wait and retry\n",
        "            try:\n",
        "                print(\"Waiting 10 seconds and retrying...\")\n",
        "                time.sleep(10)\n",
        "                drive.mount('/content/drive', force_remount=True)\n",
        "                mount_success = True\n",
        "                print(\"‚úì Retry mount successful\")\n",
        "            except Exception as e3:\n",
        "                print(f\"All mount strategies failed: {e3}\")\n",
        "                print(\"Continuing with local storage...\")\n",
        "                mount_success = False\n",
        "\n",
        "    # Verify drive access or create local fallback\n",
        "    if mount_success and Path('/content/drive/MyDrive').exists():\n",
        "        print(\"‚úì Google Drive mounted successfully\")\n",
        "    else:\n",
        "        print(\"‚ö† Using local storage instead of Google Drive\")\n",
        "        DRIVE_PATH = BASE_PATH / 'SwellSight'\n",
        "        print(f\"‚úì Local directory structure will be created: {DRIVE_PATH}\")\n",
        "else:\n",
        "    print(\"Not running in Google Colab. Using local storage.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-rwXTNz6-a_"
      },
      "source": [
        "## 4. Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sltyJmYs6-bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db243d09-2537-427b-bc0c-455b27043b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "This may take several minutes...\n",
            "\n",
            "Installing torch>=2.0.0...\n",
            "‚úì torch installed successfully\n",
            "Installing torchvision>=0.15.0...\n",
            "‚úì torchvision installed successfully\n",
            "Installing torchaudio>=2.0.0...\n",
            "‚úì torchaudio installed successfully\n",
            "Installing transformers>=4.30.0...\n",
            "‚úì transformers installed successfully\n",
            "Installing diffusers>=0.20.0...\n",
            "‚úì diffusers installed successfully\n",
            "Installing accelerate>=0.20.0...\n",
            "‚úì accelerate installed successfully\n",
            "Installing opencv-python>=4.8.0...\n",
            "‚úì opencv-python installed successfully\n",
            "Installing Pillow>=9.5.0...\n",
            "‚úì Pillow installed successfully\n",
            "Installing scikit-image>=0.20.0...\n",
            "‚úì scikit-image installed successfully\n",
            "Installing controlnet-aux>=0.0.6...\n",
            "‚úì controlnet-aux installed successfully\n",
            "Installing timm>=0.9.0...\n",
            "‚úì timm installed successfully\n",
            "Installing einops>=0.6.0...\n",
            "‚úì einops installed successfully\n",
            "Installing omegaconf>=2.3.0...\n",
            "‚úì omegaconf installed successfully\n",
            "Installing xformers>=0.0.20...\n",
            "‚úì xformers installed successfully\n",
            "Installing invisible-watermark>=0.2.0...\n",
            "‚úì invisible-watermark installed successfully\n",
            "Installing safetensors>=0.3.0...\n",
            "‚úì safetensors installed successfully\n",
            "Installing numpy>=1.24.0...\n",
            "‚úì numpy installed successfully\n",
            "Installing pandas>=2.0.0...\n",
            "‚úì pandas installed successfully\n",
            "Installing matplotlib>=3.7.0...\n",
            "‚úì matplotlib installed successfully\n",
            "Installing seaborn>=0.12.0...\n",
            "‚úì seaborn installed successfully\n",
            "Installing plotly>=5.14.0...\n",
            "‚úì plotly installed successfully\n",
            "Installing scipy>=1.10.0...\n",
            "‚úì scipy installed successfully\n",
            "Installing scikit-learn>=1.3.0...\n",
            "‚úì scikit-learn installed successfully\n",
            "Installing tqdm>=4.65.0...\n",
            "‚úì tqdm installed successfully\n",
            "Installing ipywidgets>=8.0.0...\n",
            "‚úì ipywidgets installed successfully\n",
            "\n",
            "‚úì Package installation completed\n"
          ]
        }
      ],
      "source": [
        "# Core ML and Computer Vision packages\n",
        "packages_to_install = [\n",
        "    # Core ML frameworks\n",
        "    'torch>=2.0.0',\n",
        "    'torchvision>=0.15.0',\n",
        "    'torchaudio>=2.0.0',\n",
        "    'transformers>=4.30.0',\n",
        "    'diffusers>=0.20.0',\n",
        "    'accelerate>=0.20.0',\n",
        "\n",
        "    # Computer Vision\n",
        "    'opencv-python>=4.8.0',\n",
        "    'Pillow>=9.5.0',\n",
        "    'scikit-image>=0.20.0',\n",
        "    'controlnet-aux>=0.0.6',\n",
        "\n",
        "    # MiDaS dependencies\n",
        "    'timm>=0.9.0',\n",
        "    'einops>=0.6.0',\n",
        "    'omegaconf>=2.3.0',\n",
        "\n",
        "    # ControlNet dependencies\n",
        "    'xformers>=0.0.20',\n",
        "    'invisible-watermark>=0.2.0',\n",
        "    'safetensors>=0.3.0',\n",
        "\n",
        "    # Data Science and Analysis\n",
        "    'numpy>=1.24.0',\n",
        "    'pandas>=2.0.0',\n",
        "    'matplotlib>=3.7.0',\n",
        "    'seaborn>=0.12.0',\n",
        "    'plotly>=5.14.0',\n",
        "    'scipy>=1.10.0',\n",
        "    'scikit-learn>=1.3.0',\n",
        "\n",
        "    # Utilities\n",
        "    'tqdm>=4.65.0',\n",
        "    'ipywidgets>=8.0.0'\n",
        "]\n",
        "\n",
        "print(\"Installing required packages...\")\n",
        "print(\"This may take several minutes...\\n\")\n",
        "\n",
        "for package in packages_to_install:\n",
        "    try:\n",
        "        print(f\"Installing {package}...\")\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, '-m', 'pip', 'install', package, '--quiet'],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úì {package.split('>=')[0]} installed successfully\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Optional package {package} failed: {result.stderr}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error installing {package}: {e}\")\n",
        "\n",
        "print(\"\\n‚úì Package installation completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkFFvOtl6-bB"
      },
      "source": [
        "## 5. Import Core Libraries and Verify Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Aaxjo1O6-bC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab5dbcf-499d-46d6-bc77-c2888cfff367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì PyTorch: 2.9.0+cu126\n",
            "‚úì Torchvision: 0.24.0+cu126\n",
            "‚úì Transformers: Available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Diffusers: Available (ControlNet support)\n",
            "‚úì OpenCV: 4.12.0\n",
            "‚úì PIL: Available\n",
            "‚úì NumPy: 2.0.2\n",
            "‚úì Pandas: 2.2.2\n",
            "‚úì Matplotlib: Available\n",
            "‚úì Seaborn: Available\n",
            "‚úì SciPy: Available\n",
            "‚úì Scikit-learn: Available\n",
            "‚úì TQDM: Available\n",
            "‚úì IPyWidgets: Available\n",
            "\n",
            "‚úÖ All core libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import and verify core libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    # Core ML libraries\n",
        "    import torch\n",
        "    import torchvision\n",
        "    from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
        "    print(f\"‚úì PyTorch: {torch.__version__}\")\n",
        "    print(f\"‚úì Torchvision: {torchvision.__version__}\")\n",
        "    print(f\"‚úì Transformers: Available\")\n",
        "\n",
        "    # Try importing diffusers for ControlNet\n",
        "    try:\n",
        "        from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "        print(f\"‚úì Diffusers: Available (ControlNet support)\")\n",
        "        CONTROLNET_AVAILABLE = True\n",
        "    except ImportError:\n",
        "        print(f\"‚ö† Diffusers: Not available (will use fallback generation)\")\n",
        "        CONTROLNET_AVAILABLE = False\n",
        "\n",
        "    # Computer Vision libraries\n",
        "    import cv2\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    print(f\"‚úì OpenCV: {cv2.__version__}\")\n",
        "    print(f\"‚úì PIL: Available\")\n",
        "    print(f\"‚úì NumPy: {np.__version__}\")\n",
        "\n",
        "    # Data Science libraries\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from scipy import stats\n",
        "    from sklearn.metrics import mean_absolute_error, accuracy_score\n",
        "    print(f\"‚úì Pandas: {pd.__version__}\")\n",
        "    print(f\"‚úì Matplotlib: Available\")\n",
        "    print(f\"‚úì Seaborn: Available\")\n",
        "    print(f\"‚úì SciPy: Available\")\n",
        "    print(f\"‚úì Scikit-learn: Available\")\n",
        "\n",
        "    # Utilities\n",
        "    from tqdm.auto import tqdm\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, HTML, clear_output\n",
        "    print(f\"‚úì TQDM: Available\")\n",
        "    print(f\"‚úì IPyWidgets: Available\")\n",
        "\n",
        "    print(\"\\n‚úÖ All core libraries imported successfully!\")\n",
        "\n",
        "    # Update GPU detection with imported torch\n",
        "    if DEVICE is None:\n",
        "        gpu_available = torch.cuda.is_available()\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        DEVICE = torch.device('cuda:0' if gpu_available else 'cpu')\n",
        "        print(f\"\\nüöÄ GPU Status: {DEVICE}\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please run the package installation cell again.\")\n",
        "    CONTROLNET_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSkWrkCPgSyg"
      },
      "source": [
        "## 6. Directory Structure Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I8oR7E-gSyh",
        "outputId": "17d8ce01-7957-4d51-d202-16cbb51264ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating pipeline directory structure...\n",
            "\n",
            "üìÅ Created 0 new directories:\n",
            "\n",
            "üìÇ Found 12 existing directories:\n",
            "   üìÅ data                      - Main data directory\n",
            "   üìÅ data/real                 - Real beach camera images\n",
            "   üìÅ data/real/images          - Input real images\n",
            "   üìÅ data/depth_maps           - MiDaS extracted depth maps\n",
            "   üìÅ data/synthetic            - Generated synthetic images\n",
            "   üìÅ data/synthetic/images     - Synthetic image outputs\n",
            "   üìÅ data/synthetic/labels     - Synthetic image metadata\n",
            "   üìÅ data/metadata             - Pipeline metadata and configs\n",
            "   üìÅ checkpoints               - Model checkpoints and saved states\n",
            "   üìÅ logs                      - Pipeline execution logs\n",
            "   üìÅ results                   - Analysis results and reports\n",
            "   üìÅ models                    - Downloaded model files\n",
            "\n",
            "üèóÔ∏è  Directory structure created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create directory structure for pipeline data\n",
        "print(\"Creating pipeline directory structure...\")\n",
        "\n",
        "# Base directories from real_to_synthetic_pipeline.py\n",
        "base_dirs = {\n",
        "    'data': 'Main data directory',\n",
        "    'data/real': 'Real beach camera images',\n",
        "    'data/real/images': 'Input real images',\n",
        "    'data/depth_maps': 'MiDaS extracted depth maps',\n",
        "    'data/synthetic': 'Generated synthetic images',\n",
        "    'data/synthetic/images': 'Synthetic image outputs',\n",
        "    'data/synthetic/labels': 'Synthetic image metadata',\n",
        "    'data/metadata': 'Pipeline metadata and configs',\n",
        "    'checkpoints': 'Model checkpoints and saved states',\n",
        "    'logs': 'Pipeline execution logs',\n",
        "    'results': 'Analysis results and reports',\n",
        "    'models': 'Downloaded model files'\n",
        "}\n",
        "\n",
        "created_dirs = []\n",
        "existing_dirs = []\n",
        "\n",
        "# Change to DRIVE_PATH for directory creation\n",
        "os.chdir(DRIVE_PATH.parent)\n",
        "DRIVE_PATH.mkdir(exist_ok=True)\n",
        "os.chdir(DRIVE_PATH)\n",
        "\n",
        "for dir_path, description in base_dirs.items():\n",
        "    full_path = Path(dir_path)\n",
        "    if full_path.exists():\n",
        "        existing_dirs.append((dir_path, description))\n",
        "    else:\n",
        "        full_path.mkdir(parents=True, exist_ok=True)\n",
        "        created_dirs.append((dir_path, description))\n",
        "\n",
        "print(f\"\\nüìÅ Created {len(created_dirs)} new directories:\")\n",
        "for dir_path, description in created_dirs:\n",
        "    print(f\"   ‚úÖ {dir_path:<25} - {description}\")\n",
        "\n",
        "if existing_dirs:\n",
        "    print(f\"\\nüìÇ Found {len(existing_dirs)} existing directories:\")\n",
        "    for dir_path, description in existing_dirs:\n",
        "        print(f\"   üìÅ {dir_path:<25} - {description}\")\n",
        "\n",
        "# Create .gitkeep files for empty directories\n",
        "empty_dirs = ['data/real/images', 'checkpoints', 'logs']\n",
        "for dir_path in empty_dirs:\n",
        "    gitkeep_path = Path(dir_path) / '.gitkeep'\n",
        "    if not gitkeep_path.exists():\n",
        "        gitkeep_path.touch()\n",
        "\n",
        "print(\"\\nüèóÔ∏è  Directory structure created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVrnM9Po6-bE"
      },
      "source": [
        "## 7. Global Configuration Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "thmmG3_X6-bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa292fa3-d2ed-4e7b-c0e9-16482a4b747d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration saved to: data/metadata/pipeline_config.json\n",
            "\n",
            "‚öôÔ∏è  Pipeline Configuration Summary:\n",
            "   üìä Max images to process: 800\n",
            "   üé® Synthetic per real image: 3\n",
            "   üß† Default MiDaS model: Intel/dpt-large\n",
            "   üéØ Default ControlNet: lllyasviel/sd-controlnet-depth\n",
            "   üìè Quality threshold: 0.3\n",
            "   Session ID: swellsight_20260109_162959\n",
            "   Platform: COLAB\n",
            "   Device: cuda:0\n",
            "\n",
            "üéõÔ∏è  Configuration setup completed!\n"
          ]
        }
      ],
      "source": [
        "# Global configuration dictionary\n",
        "CONFIG = {\n",
        "    # Environment settings\n",
        "    'environment': {\n",
        "        'platform': 'colab' if IN_COLAB else 'kaggle' if IS_KAGGLE else 'local',\n",
        "        'device': str(DEVICE),\n",
        "        'gpu_available': gpu_available,\n",
        "        'gpu_count': gpu_count if gpu_available else 0,\n",
        "        'controlnet_available': CONTROLNET_AVAILABLE\n",
        "    },\n",
        "\n",
        "    # Path configuration\n",
        "    'paths': {\n",
        "        'base_path': str(BASE_PATH),\n",
        "        'drive_path': str(DRIVE_PATH),\n",
        "        'data_path': str(DRIVE_PATH / 'data'),\n",
        "        'real_images_path': str(DRIVE_PATH / 'data' / 'real' / 'images'),\n",
        "        'depth_maps_path': str(DRIVE_PATH / 'data' / 'depth_maps'),\n",
        "        'synthetic_data_path': str(DRIVE_PATH / 'data' / 'synthetic'),\n",
        "        'metadata_path': str(DRIVE_PATH / 'data' / 'metadata'),\n",
        "        'models_path': str(DRIVE_PATH / 'models'),\n",
        "        'checkpoints_path': str(DRIVE_PATH / 'checkpoints'),\n",
        "        'results_path': str(DRIVE_PATH / 'results'),\n",
        "        'logs_path': str(DRIVE_PATH / 'logs')\n",
        "    },\n",
        "\n",
        "    # Model configuration\n",
        "    'models': {\n",
        "        'midas': {\n",
        "            'default': 'Intel/dpt-large',\n",
        "            'alternatives': ['Intel/dpt-hybrid-midas', 'Intel/dpt-base'],\n",
        "            'description': 'MiDaS depth estimation models'\n",
        "        },\n",
        "        'controlnet': {\n",
        "            'default': 'lllyasviel/sd-controlnet-depth',\n",
        "            'description': 'ControlNet depth-conditioned generation'\n",
        "        },\n",
        "        'stable_diffusion_model': 'runwayml/stable-diffusion-v1-5'\n",
        "    },\n",
        "\n",
        "    # Processing parameters\n",
        "    'processing': {\n",
        "        'max_images': 800,\n",
        "        'synthetic_per_real': 3,\n",
        "        'batch_size': 1,\n",
        "        'image_size': [768, 768],\n",
        "        'max_images_per_session': 500,\n",
        "        'checkpoint_interval': 10,\n",
        "        'quality_threshold': 0.3,\n",
        "        'image_extensions': ['jpg', 'jpeg', 'png', 'bmp']\n",
        "    },\n",
        "\n",
        "    # Device configuration\n",
        "    'device': {\n",
        "        'auto_detect': True,\n",
        "        'preferred': 'cuda',\n",
        "        'fallback': 'cpu'\n",
        "    },\n",
        "\n",
        "    # Augmentation parameters\n",
        "    'augmentation': {\n",
        "        'enabled': True,\n",
        "        'parameters': {\n",
        "            'guidance_scale': 7.5,\n",
        "            'num_inference_steps': 20,\n",
        "            'controlnet_conditioning_scale': 1.0\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Quality thresholds\n",
        "    'quality': {\n",
        "        'min_overall_quality': 0.5,\n",
        "        'min_diversity_score': 0.3,\n",
        "        'min_balance_score': 0.2,\n",
        "        'drift_threshold': 0.1\n",
        "    },\n",
        "\n",
        "    # Session metadata\n",
        "    'session': {\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'session_id': f\"swellsight_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "        'version': '1.0'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save configuration\n",
        "config_path = Path('data/metadata/pipeline_config.json')\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Configuration saved to: {config_path}\")\n",
        "\n",
        "# Display key settings\n",
        "print(\"\\n‚öôÔ∏è  Pipeline Configuration Summary:\")\n",
        "print(f\"   üìä Max images to process: {CONFIG['processing']['max_images']}\")\n",
        "print(f\"   üé® Synthetic per real image: {CONFIG['processing']['synthetic_per_real']}\")\n",
        "print(f\"   üß† Default MiDaS model: {CONFIG['models']['midas']['default']}\")\n",
        "print(f\"   üéØ Default ControlNet: {CONFIG['models']['controlnet']['default']}\")\n",
        "print(f\"   üìè Quality threshold: {CONFIG['processing']['quality_threshold']}\")\n",
        "print(f\"   Session ID: {CONFIG['session']['session_id']}\")\n",
        "print(f\"   Platform: {CONFIG['environment']['platform'].upper()}\")\n",
        "print(f\"   Device: {CONFIG['environment']['device']}\")\n",
        "\n",
        "# Store config for other notebooks\n",
        "PIPELINE_CONFIG = CONFIG\n",
        "globals()['SWELLSIGHT_CONFIG'] = CONFIG\n",
        "\n",
        "print(\"\\nüéõÔ∏è  Configuration setup completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKCX5Sp_gSyi"
      },
      "source": [
        "## 8. SwellSight Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqQs-hx5gSyj",
        "outputId": "da8083b7-0033-4740-a5b4-f65308b7a3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing SwellSight package...\n",
            "‚ö†Ô∏è  SwellSight root directory not found\n",
            "   Please ensure you're running this notebook from within the SwellSight project\n",
            "\n",
            "üì¶ SwellSight package setup completed!\n"
          ]
        }
      ],
      "source": [
        "# Install SwellSight package in development mode\n",
        "print(\"Installing SwellSight package...\")\n",
        "\n",
        "# Check if we're in the SwellSight directory\n",
        "current_dir = Path.cwd()\n",
        "swellsight_root = None\n",
        "\n",
        "# Look for setup.py or pyproject.toml\n",
        "for parent in [current_dir] + list(current_dir.parents):\n",
        "    if (parent / 'setup.py').exists() or (parent / 'pyproject.toml').exists():\n",
        "        if (parent / 'swellsight').exists():  # Check for swellsight package\n",
        "            swellsight_root = parent\n",
        "            break\n",
        "\n",
        "if swellsight_root:\n",
        "    print(f\"üìÅ Found SwellSight root: {swellsight_root}\")\n",
        "\n",
        "    # Install in development mode\n",
        "    try:\n",
        "        os.chdir(swellsight_root)\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\", \"--quiet\"])\n",
        "        print(\"‚úÖ SwellSight package installed in development mode\")\n",
        "\n",
        "        # Test import\n",
        "        try:\n",
        "            from swellsight.data.midas_depth_extractor import MiDaSDepthExtractor\n",
        "            from swellsight.data.controlnet_generator import ControlNetSyntheticGenerator, AugmentationParameterSystem\n",
        "            print(\"‚úÖ SwellSight imports successful\")\n",
        "\n",
        "            # Store configuration\n",
        "            SWELLSIGHT_ROOT = swellsight_root\n",
        "            print(f\"üìã SwellSight root path: {SWELLSIGHT_ROOT}\")\n",
        "\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ö†Ô∏è  SwellSight import warning: {e}\")\n",
        "            print(\"   This may be normal if dependencies are still being set up\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå SwellSight installation failed: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  SwellSight root directory not found\")\n",
        "    print(\"   Please ensure you're running this notebook from within the SwellSight project\")\n",
        "    SWELLSIGHT_ROOT = current_dir\n",
        "\n",
        "print(\"\\nüì¶ SwellSight package setup completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0oSy6DM6-bG"
      },
      "source": [
        "## 9. Logging Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J9u9j3wr6-bH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d55655b-d875-4c27-b2f3-ac5f0c03b338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-09 16:30:00 - SwellSight - INFO - SwellSight logging system initialized\n",
            "INFO:SwellSight:SwellSight logging system initialized\n",
            "2026-01-09 16:30:00 - SwellSight - INFO - Session ID: swellsight_20260109_162959\n",
            "INFO:SwellSight:Session ID: swellsight_20260109_162959\n",
            "2026-01-09 16:30:00 - SwellSight - INFO - Log file: /content/drive/MyDrive/SwellSight/logs/swellsight_20260109_163000.log\n",
            "INFO:SwellSight:Log file: /content/drive/MyDrive/SwellSight/logs/swellsight_20260109_163000.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Logging configured\n",
            "  Log file: /content/drive/MyDrive/SwellSight/logs/swellsight_20260109_163000.log\n"
          ]
        }
      ],
      "source": [
        "# Configure logging\n",
        "log_file = DRIVE_PATH / 'logs' / f\"swellsight_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
        "\n",
        "# Create logger\n",
        "logger = logging.getLogger('SwellSight')\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Clear any existing handlers\n",
        "logger.handlers.clear()\n",
        "\n",
        "# Create formatters\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "\n",
        "# File handler\n",
        "file_handler = logging.FileHandler(log_file)\n",
        "file_handler.setLevel(logging.INFO)\n",
        "file_handler.setFormatter(formatter)\n",
        "logger.addHandler(file_handler)\n",
        "\n",
        "# Console handler for Jupyter\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "console_handler.setFormatter(formatter)\n",
        "logger.addHandler(console_handler)\n",
        "\n",
        "# Test logging\n",
        "logger.info(\"SwellSight logging system initialized\")\n",
        "logger.info(f\"Session ID: {CONFIG['session']['session_id']}\")\n",
        "logger.info(f\"Log file: {log_file}\")\n",
        "\n",
        "print(f\"‚úì Logging configured\")\n",
        "print(f\"  Log file: {log_file}\")\n",
        "\n",
        "# Make logger globally available\n",
        "globals()['SWELLSIGHT_LOGGER'] = logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQO80Prs6-bI"
      },
      "source": [
        "## 10. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "obDEir_S6-bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a2ae55-5acc-454c-a41a-00080a898c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Utility functions defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-09 16:30:00 - SwellSight - INFO - Checkpoint saved: setup_test -> /content/drive/MyDrive/SwellSight/checkpoints/setup_test.json\n",
            "INFO:SwellSight:Checkpoint saved: setup_test -> /content/drive/MyDrive/SwellSight/checkpoints/setup_test.json\n",
            "2026-01-09 16:30:00 - SwellSight - INFO - Checkpoint loaded: setup_test from /content/drive/MyDrive/SwellSight/checkpoints/setup_test.json\n",
            "INFO:SwellSight:Checkpoint loaded: setup_test from /content/drive/MyDrive/SwellSight/checkpoints/setup_test.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Checkpoint system tested: True\n"
          ]
        }
      ],
      "source": [
        "def save_checkpoint(data, checkpoint_name, description=\"\"):\n",
        "    \"\"\"Save checkpoint data to drive.\"\"\"\n",
        "    checkpoint_file = DRIVE_PATH / 'checkpoints' / f\"{checkpoint_name}.json\"\n",
        "\n",
        "    checkpoint_data = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'session_id': CONFIG['session']['session_id'],\n",
        "        'checkpoint_name': checkpoint_name,\n",
        "        'description': description,\n",
        "        'data': data\n",
        "    }\n",
        "\n",
        "    with open(checkpoint_file, 'w') as f:\n",
        "        json.dump(checkpoint_data, f, indent=2, default=str)\n",
        "\n",
        "    logger.info(f\"Checkpoint saved: {checkpoint_name} -> {checkpoint_file}\")\n",
        "    return checkpoint_file\n",
        "\n",
        "def load_checkpoint(checkpoint_name):\n",
        "    \"\"\"Load checkpoint data from drive.\"\"\"\n",
        "    checkpoint_file = DRIVE_PATH / 'checkpoints' / f\"{checkpoint_name}.json\"\n",
        "\n",
        "    if checkpoint_file.exists():\n",
        "        with open(checkpoint_file, 'r') as f:\n",
        "            checkpoint_data = json.load(f)\n",
        "\n",
        "        logger.info(f\"Checkpoint loaded: {checkpoint_name} from {checkpoint_file}\")\n",
        "        return checkpoint_data['data']\n",
        "    else:\n",
        "        logger.warning(f\"Checkpoint not found: {checkpoint_name}\")\n",
        "        return None\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory cache.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        logger.info(\"GPU memory cache cleared\")\n",
        "\n",
        "def get_memory_usage():\n",
        "    \"\"\"Get current memory usage information.\"\"\"\n",
        "    import psutil\n",
        "\n",
        "    # System memory\n",
        "    memory = psutil.virtual_memory()\n",
        "    memory_info = {\n",
        "        'system_memory_total_gb': memory.total / 1024**3,\n",
        "        'system_memory_used_gb': memory.used / 1024**3,\n",
        "        'system_memory_percent': memory.percent\n",
        "    }\n",
        "\n",
        "    # GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        gpu_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        gpu_cached = torch.cuda.memory_reserved(0) / 1024**3\n",
        "\n",
        "        memory_info.update({\n",
        "            'gpu_memory_total_gb': gpu_memory,\n",
        "            'gpu_memory_allocated_gb': gpu_allocated,\n",
        "            'gpu_memory_cached_gb': gpu_cached,\n",
        "            'gpu_memory_free_gb': gpu_memory - gpu_cached\n",
        "        })\n",
        "\n",
        "    return memory_info\n",
        "\n",
        "def display_progress_widget(description=\"Processing...\"):\n",
        "    \"\"\"Create and display a progress widget.\"\"\"\n",
        "    progress_bar = widgets.IntProgress(\n",
        "        value=0,\n",
        "        min=0,\n",
        "        max=100,\n",
        "        description=description,\n",
        "        bar_style='info',\n",
        "        style={'bar_color': '#1f77b4'},\n",
        "        orientation='horizontal'\n",
        "    )\n",
        "\n",
        "    status_label = widgets.Label(value=\"Initializing...\")\n",
        "\n",
        "    display(widgets.VBox([progress_bar, status_label]))\n",
        "\n",
        "    return progress_bar, status_label\n",
        "\n",
        "print(\"‚úì Utility functions defined\")\n",
        "\n",
        "# Test checkpoint functionality\n",
        "test_data = {'setup_completed': True, 'timestamp': datetime.now().isoformat()}\n",
        "save_checkpoint(test_data, 'setup_test', 'Setup completion test')\n",
        "loaded_data = load_checkpoint('setup_test')\n",
        "print(f\"‚úì Checkpoint system tested: {loaded_data['setup_completed']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtjpYfeRgSyl"
      },
      "source": [
        "## 11. Final Verification and Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUWW77QPgSym",
        "outputId": "a920393d-6eff-40d8-911f-f25d0027ca6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Performing final setup verification...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-09 16:30:05 - SwellSight - INFO - Setup and installation completed successfully\n",
            "INFO:SwellSight:Setup and installation completed successfully\n",
            "2026-01-09 16:30:05 - SwellSight - INFO - System ready for pipeline execution\n",
            "INFO:SwellSight:System ready for pipeline execution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Setup Verification Results:\n",
            "==================================================\n",
            "Environment         : ‚úÖ Ready\n",
            "GPU                 : ‚úÖ Tesla T4\n",
            "Core Dependencies   : ‚úÖ Installed\n",
            "MiDaS               : ‚úÖ Ready\n",
            "ControlNet          : ‚úÖ Ready\n",
            "SwellSight Package  : ‚ö†Ô∏è  Import issues (may be normal)\n",
            "Directory Structure : ‚úÖ Created\n",
            "Configuration       : ‚úÖ Saved\n",
            "\n",
            "==================================================\n",
            "üéâ SETUP COMPLETED SUCCESSFULLY!\n",
            "\n",
            "‚úÖ Ready to proceed to the next notebook:\n",
            "   üìì 02_Data_Import_and_Preprocessing.ipynb\n",
            "\n",
            "‚ö†Ô∏è  Note: 1 components have warnings but should work\n",
            "\n",
            "üìö Next Steps:\n",
            "   1. Place real beach images in data/real/images/\n",
            "   2. Run 02_Data_Import_and_Preprocessing.ipynb\n",
            "   3. Execute the full pipeline with 03_MiDaS_Depth_Extraction.ipynb\n",
            "\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "SWELLSIGHT SETUP COMPLETED SUCCESSFULLY\n",
            "============================================================\n",
            "\n",
            "üìã Session Information:\n",
            "  Session ID: swellsight_20260109_162959\n",
            "  Platform: COLAB\n",
            "  Created: 2026-01-09T16:29:59.012570\n",
            "\n",
            "üñ•Ô∏è  Hardware Configuration:\n",
            "  Device: cuda:0\n",
            "  GPU Available: True\n",
            "  GPU Count: 1\n",
            "  GPU Memory: 14.7 GB\n",
            "  System Memory: 51.0 GB\n",
            "\n",
            "üîß Software Configuration:\n",
            "  PyTorch: 2.9.0+cu126\n",
            "  ControlNet Available: True\n",
            "  MiDaS Model: Intel/dpt-large\n",
            "\n",
            "üìÅ Directory Structure:\n",
            "  Data Path: /content/drive/MyDrive/SwellSight/data\n",
            "  Models Path: /content/drive/MyDrive/SwellSight/models\n",
            "  Checkpoints Path: /content/drive/MyDrive/SwellSight/checkpoints\n",
            "\n",
            "üìä Processing Configuration:\n",
            "  Batch Size: 1\n",
            "  Image Size: [768, 768]\n",
            "  Max Images per Session: 500\n",
            "\n",
            "‚úÖ Ready for next notebook: 02_Data_Import_and_Preprocessing.ipynb\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026-01-09 16:30:05 - SwellSight - INFO - Checkpoint saved: setup_completed -> /content/drive/MyDrive/SwellSight/checkpoints/setup_completed.json\n",
            "INFO:SwellSight:Checkpoint saved: setup_completed -> /content/drive/MyDrive/SwellSight/checkpoints/setup_completed.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/SwellSight/checkpoints/setup_completed.json')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Final verification of setup\n",
        "print(\"üîç Performing final setup verification...\\n\")\n",
        "\n",
        "verification_results = {\n",
        "    \"Environment\": \"‚úÖ Ready\",\n",
        "    \"GPU\": \"‚ùì Checking...\",\n",
        "    \"Core Dependencies\": \"‚ùì Checking...\",\n",
        "    \"MiDaS\": \"‚ùì Checking...\",\n",
        "    \"ControlNet\": \"‚ùì Checking...\",\n",
        "    \"SwellSight Package\": \"‚ùì Checking...\",\n",
        "    \"Directory Structure\": \"‚ùì Checking...\",\n",
        "    \"Configuration\": \"‚ùì Checking...\"\n",
        "}\n",
        "\n",
        "# GPU Check\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        verification_results[\"GPU\"] = f\"‚úÖ {torch.cuda.get_device_name()}\"\n",
        "    else:\n",
        "        verification_results[\"GPU\"] = \"‚ö†Ô∏è  CPU only\"\n",
        "except:\n",
        "    verification_results[\"GPU\"] = \"‚ùå PyTorch not available\"\n",
        "\n",
        "# Core Dependencies Check\n",
        "try:\n",
        "    import torch, torchvision, transformers, diffusers\n",
        "    verification_results[\"Core Dependencies\"] = \"‚úÖ Installed\"\n",
        "except ImportError as e:\n",
        "    verification_results[\"Core Dependencies\"] = f\"‚ùå Missing: {e}\"\n",
        "\n",
        "# MiDaS Check\n",
        "try:\n",
        "    import timm\n",
        "    verification_results[\"MiDaS\"] = \"‚úÖ Ready\"\n",
        "except ImportError:\n",
        "    verification_results[\"MiDaS\"] = \"‚ùå Dependencies missing\"\n",
        "\n",
        "# ControlNet Check\n",
        "try:\n",
        "    from diffusers import StableDiffusionControlNetPipeline\n",
        "    verification_results[\"ControlNet\"] = \"‚úÖ Ready\"\n",
        "except ImportError:\n",
        "    verification_results[\"ControlNet\"] = \"‚ùå Diffusers not available\"\n",
        "\n",
        "# SwellSight Package Check\n",
        "try:\n",
        "    from swellsight.data.midas_depth_extractor import MiDaSDepthExtractor\n",
        "    verification_results[\"SwellSight Package\"] = \"‚úÖ Installed\"\n",
        "except ImportError:\n",
        "    verification_results[\"SwellSight Package\"] = \"‚ö†Ô∏è  Import issues (may be normal)\"\n",
        "\n",
        "# Directory Structure Check\n",
        "required_dirs = ['data/real/images', 'data/synthetic', 'data/depth_maps']\n",
        "if all(Path(d).exists() for d in required_dirs):\n",
        "    verification_results[\"Directory Structure\"] = \"‚úÖ Created\"\n",
        "else:\n",
        "    verification_results[\"Directory Structure\"] = \"‚ùå Missing directories\"\n",
        "\n",
        "# Configuration Check\n",
        "if Path('data/metadata/pipeline_config.json').exists():\n",
        "    verification_results[\"Configuration\"] = \"‚úÖ Saved\"\n",
        "else:\n",
        "    verification_results[\"Configuration\"] = \"‚ùå Not saved\"\n",
        "\n",
        "# Display results\n",
        "print(\"üìã Setup Verification Results:\")\n",
        "print(\"=\" * 50)\n",
        "for component, status in verification_results.items():\n",
        "    print(f\"{component:<20}: {status}\")\n",
        "\n",
        "# Overall status\n",
        "failed_components = [k for k, v in verification_results.items() if v.startswith(\"‚ùå\")]\n",
        "warning_components = [k for k, v in verification_results.items() if v.startswith(\"‚ö†Ô∏è\")]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "if not failed_components:\n",
        "    print(\"üéâ SETUP COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"\\n‚úÖ Ready to proceed to the next notebook:\")\n",
        "    print(\"   üìì 02_Data_Import_and_Preprocessing.ipynb\")\n",
        "\n",
        "    if warning_components:\n",
        "        print(f\"\\n‚ö†Ô∏è  Note: {len(warning_components)} components have warnings but should work\")\n",
        "else:\n",
        "    print(f\"‚ùå SETUP INCOMPLETE - {len(failed_components)} components failed\")\n",
        "    print(\"\\nüîß Please resolve the following issues:\")\n",
        "    for component in failed_components:\n",
        "        print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\nüìö Next Steps:\")\n",
        "print(\"   1. Place real beach images in data/real/images/\")\n",
        "print(\"   2. Run 02_Data_Import_and_Preprocessing.ipynb\")\n",
        "print(\"   3. Execute the full pipeline with 03_MiDaS_Depth_Extraction.ipynb\")\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# Display comprehensive system status\n",
        "memory_info = get_memory_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SWELLSIGHT SETUP COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüìã Session Information:\")\n",
        "print(f\"  Session ID: {CONFIG['session']['session_id']}\")\n",
        "print(f\"  Platform: {CONFIG['environment']['platform'].upper()}\")\n",
        "print(f\"  Created: {CONFIG['session']['created_at']}\")\n",
        "\n",
        "print(f\"\\nüñ•Ô∏è  Hardware Configuration:\")\n",
        "print(f\"  Device: {CONFIG['environment']['device']}\")\n",
        "print(f\"  GPU Available: {CONFIG['environment']['gpu_available']}\")\n",
        "if CONFIG['environment']['gpu_available']:\n",
        "    print(f\"  GPU Count: {CONFIG['environment']['gpu_count']}\")\n",
        "    print(f\"  GPU Memory: {memory_info.get('gpu_memory_total_gb', 0):.1f} GB\")\n",
        "print(f\"  System Memory: {memory_info['system_memory_total_gb']:.1f} GB\")\n",
        "\n",
        "print(f\"\\nüîß Software Configuration:\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  ControlNet Available: {CONFIG['environment']['controlnet_available']}\")\n",
        "print(f\"  MiDaS Model: {CONFIG['models']['midas']['default']}\")\n",
        "\n",
        "print(f\"\\nüìÅ Directory Structure:\")\n",
        "print(f\"  Data Path: {CONFIG['paths']['data_path']}\")\n",
        "print(f\"  Models Path: {CONFIG['paths']['models_path']}\")\n",
        "print(f\"  Checkpoints Path: {CONFIG['paths']['checkpoints_path']}\")\n",
        "\n",
        "print(f\"\\nüìä Processing Configuration:\")\n",
        "print(f\"  Batch Size: {CONFIG['processing']['batch_size']}\")\n",
        "print(f\"  Image Size: {CONFIG['processing']['image_size']}\")\n",
        "print(f\"  Max Images per Session: {CONFIG['processing']['max_images_per_session']}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Ready for next notebook: 02_Data_Import_and_Preprocessing.ipynb\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Log completion\n",
        "logger.info(\"Setup and installation completed successfully\")\n",
        "logger.info(f\"System ready for pipeline execution\")\n",
        "\n",
        "# Save setup completion checkpoint\n",
        "setup_completion_data = {\n",
        "    'setup_completed': True,\n",
        "    'config': CONFIG,\n",
        "    'memory_info': memory_info,\n",
        "    'completion_time': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "save_checkpoint(setup_completion_data, 'setup_completed', 'Setup and installation completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp6ApH0u6-bO"
      },
      "source": [
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "The setup is now complete! You can proceed to the next notebook:\n",
        "\n",
        "**[02_Data_Import_and_Preprocessing.ipynb](02_Data_Import_and_Preprocessing.ipynb)**\n",
        "\n",
        "This notebook will handle:\n",
        "- Loading real beach camera images\n",
        "- Data validation and quality checks\n",
        "- Metadata extraction and organization\n",
        "- Initial data exploration\n",
        "\n",
        "### Important Notes:\n",
        "- All configuration and paths are now set up in the `SWELLSIGHT_CONFIG` global variable\n",
        "- Logging is configured and available via the `SWELLSIGHT_LOGGER` global variable\n",
        "- Checkpoint system is ready for saving intermediate results\n",
        "- GPU memory management utilities are available\n",
        "\n",
        "### Troubleshooting:\n",
        "- If you encounter memory issues, use `clear_gpu_memory()` function\n",
        "- Check system status anytime with `get_memory_usage()`\n",
        "- All session data is automatically saved to Google Drive (if mounted)\n",
        "- Logs are saved to the logs directory for debugging\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}