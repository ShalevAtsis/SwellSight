{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "depth_extraction_header"
   },
   "source": [
    "# SwellSight Real-to-Synthetic Pipeline - Depth-Anything-V2 Depth Extraction\n",
    "\n",
    "This notebook implements the Depth-Anything-V2 depth estimation phase of the SwellSight real-to-synthetic generation pipeline.\n",
    "\n",
    "## Overview\n",
    "This notebook provides:\n",
    "- Depth-Anything-V2 model initialization and configuration\n",
    "- Batch depth map extraction from real beach images\n",
    "- Quality assessment and filtering of depth maps\n",
    "- Depth map visualization and analysis\n",
    "- Storage and metadata management\n",
    "- Advanced error handling and memory management\n",
    "\n",
    "## Pipeline Integration\n",
    "This notebook implements Step 1 of the pipeline:\n",
    "1. **Model Loading**: Initialize Depth-Anything-V2 depth estimation model\n",
    "2. **Batch Processing**: Extract depth maps from all valid images\n",
    "3. **Quality Control**: Apply quality thresholds and filtering\n",
    "4. **Storage**: Save depth maps with structured metadata\n",
    "\n",
    "## Depth-Anything-V2 Models Available\n",
    "- `depth-anything/Depth-Anything-V2-Large`: Best quality, higher memory usage\n",
    "- `depth-anything/Depth-Anything-V2-Base`: Balanced quality and speed\n",
    "- `depth-anything/Depth-Anything-V2-Small`: Fastest, lower memory usage\n",
    "\n",
    "## Prerequisites\n",
    "- Complete execution of `02_Data_Import_and_Preprocessing.ipynb`\n",
    "- Valid images available in processing batch\n",
    "- Sufficient GPU memory (8GB+ recommended for Large model)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyuFKUIRgY6g"
   },
   "source": [
    "## 1. Load Configuration and Processing Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jr2VIro2gY6g"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add utils to path for shared utilities\n",
    "sys.path.append(str(Path.cwd() / 'utils'))\n",
    "\n",
    "# Import shared utilities\n",
    "from config_manager import load_config\n",
    "from data_flow_manager import load_previous_results, save_stage_results\n",
    "from error_handler import retry_with_backoff, handle_gpu_memory_error\n",
    "from memory_optimizer import get_optimal_batch_size, cleanup_variables\n",
    "from progress_tracker import create_progress_bar\n",
    "from data_validator import validate_image_quality\n",
    "\n",
    "# Check if running in Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    print(\"Mounting Google Drive...\")\n",
    "\n",
    "    try:\n",
    "        # Attempt 1: Standard mount\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"‚úì Google Drive mounted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Standard mount failed: {e}\")\n",
    "\n",
    "        # Attempt 2: Force remount with extended timeout (robust fallback)\n",
    "        print(\"Trying force remount with extended timeout...\")\n",
    "        try:\n",
    "            drive.mount('/content/drive', force_remount=True, timeout_ms=300000)\n",
    "            print(\"‚úì Force remount successful\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Critical failure mounting drive: {e2}\")\n",
    "            raise\n",
    "\n",
    "    # Verify the specific project path exists\n",
    "    PROJECT_PATH = Path('/content/drive/MyDrive/SwellSight')\n",
    "    if PROJECT_PATH.exists():\n",
    "        print(f\"‚úì Project directory found: {PROJECT_PATH}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Project directory not found at: {PROJECT_PATH}\")\n",
    "else:\n",
    "    PROJECT_PATH = Path.cwd()\n",
    "    print(f\"Not running in Google Colab. Using current directory: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIsuoK2DgY6h"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üîÑ Loading configuration and processing batch...\")\n",
    "\n",
    "try:\n",
    "    # Load pipeline configuration using shared utility\n",
    "    PIPELINE_CONFIG = load_config(PROJECT_PATH / 'config.json')\n",
    "    \n",
    "    # Load processing batch from previous stage\n",
    "    PROCESSING_BATCH = load_previous_results(\n",
    "        stage_name=\"data_preprocessing\",\n",
    "        required_files=[\"processed_images.json\", \"quality_report.json\"]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Configuration and batch loaded successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load configuration or batch: {e}\")\n",
    "    print(\"Please ensure you have run the previous notebooks and have valid configuration.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Display key information\n",
    "print(f\"\\nüìã Pipeline Configuration:\")\n",
    "pipeline_name = PIPELINE_CONFIG.get('pipeline', {}).get('name', 'SwellSight Pipeline')\n",
    "default_depth_model = PIPELINE_CONFIG.get('models', {}).get('depth_model', 'depth-anything/Depth-Anything-V2-Large')\n",
    "quality_threshold = PIPELINE_CONFIG.get('processing', {}).get('quality_threshold', 0.7)\n",
    "\n",
    "print(f\"   Pipeline: {pipeline_name}\")\n",
    "print(f\"   Default Depth model: {default_depth_model}\")\n",
    "print(f\"   Quality threshold: {quality_threshold}\")\n",
    "\n",
    "print(f\"\\nüìä Processing Batch:\")\n",
    "total_images = len(PROCESSING_BATCH.get('processed_images', []))\n",
    "print(f\"   Total images: {total_images}\")\n",
    "print(f\"   Ready for processing: {total_images > 0}\")\n",
    "\n",
    "# Set up paths from config\n",
    "DEPTH_OUTPUT_PATH = Path(PIPELINE_CONFIG['paths']['output_dir']) / 'depth_maps'\n",
    "METADATA_PATH = Path(PIPELINE_CONFIG['paths']['output_dir']) / 'metadata'\n",
    "LOGS_PATH = Path(PIPELINE_CONFIG['paths']['output_dir']) / 'logs'\n",
    "\n",
    "# Ensure directories exist\n",
    "DEPTH_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "METADATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Working directories:\")\n",
    "print(f\"   Depth output: {DEPTH_OUTPUT_PATH}\")\n",
    "print(f\"   Metadata: {METADATA_PATH}\")\n",
    "print(f\"   Logs: {LOGS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlwv_bnhgY6i"
   },
   "source": [
    "## 2. Device Configuration and GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTuDCCfDgY6i"
   },
   "outputs": [],
   "source": [
    "# Configure device for Depth-Anything-V2 processing\n",
    "print(\"üîß Configuring device for Depth-Anything-V2 processing...\")\n",
    "\n",
    "# Device detection with memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "\n",
    "    print(f\"\\nüöÄ GPU Configuration:\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   GPU: {gpu_name}\")\n",
    "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "    # Memory recommendations for Depth-Anything-V2\n",
    "    if gpu_memory < 6:\n",
    "        print(\"   ‚ö†Ô∏è  Warning: Less than 6GB GPU memory. Consider using Small model.\")\n",
    "        recommended_model = \"depth-anything/Depth-Anything-V2-Small\"\n",
    "    elif gpu_memory < 12:\n",
    "        print(\"   ‚úÖ Good: Sufficient memory for Base model.\")\n",
    "        recommended_model = \"depth-anything/Depth-Anything-V2-Base\"\n",
    "    else:\n",
    "        print(\"   ‚úÖ Excellent: Sufficient memory for Large model.\")\n",
    "        recommended_model = \"depth-anything/Depth-Anything-V2-Large\"\n",
    "\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    gpu_memory = 0\n",
    "    gpu_name = \"CPU\"\n",
    "    recommended_model = \"depth-anything/Depth-Anything-V2-Small\"  # Fastest for CPU\n",
    "    print(f\"\\n‚ö†Ô∏è  CPU Configuration:\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   Recommended model: {recommended_model} (fastest for CPU)\")\n",
    "    print(f\"   Note: CPU processing will be significantly slower\")\n",
    "\n",
    "# Model selection - use recommended based on hardware\n",
    "selected_model = recommended_model\n",
    "\n",
    "print(f\"\\nüß† Model Selection:\")\n",
    "print(f\"   Default from config: {default_depth_model}\")\n",
    "print(f\"   Recommended for hardware: {recommended_model}\")\n",
    "print(f\"   Selected: {selected_model}\")\n",
    "\n",
    "if selected_model != default_depth_model:\n",
    "    print(f\"   ‚ÑπÔ∏è  Using hardware-optimized model instead of default\")\n",
    "\n",
    "# Store device configuration\n",
    "DEVICE_CONFIG = {\n",
    "    'device': device,\n",
    "    'selected_model': selected_model,\n",
    "    'gpu_memory_gb': gpu_memory,\n",
    "    'gpu_name': gpu_name\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Device configuration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXgqSCY6gY6j"
   },
   "source": [
    "## 3. Depth-Anything-V2 Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB9lN3EPgY6j"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from transformers import pipeline\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@dataclass\n",
    "class DepthResult:\n",
    "    \"\"\"Data class to store depth extraction results.\"\"\"\n",
    "    depth_map: np.ndarray\n",
    "    depth_quality_score: float\n",
    "    processing_time: float\n",
    "    model_used: str\n",
    "\n",
    "class DepthAnythingV2Extractor:\n",
    "    \"\"\"Depth-Anything-V2 depth extractor with memory optimization and error handling.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"depth-anything/Depth-Anything-V2-Large\", device=\"cuda\", storage_path=None):\n",
    "        self.device = device\n",
    "        self.storage_path = Path(storage_path) if storage_path else None\n",
    "        self.model_name = model_name\n",
    "        self.pipe = None\n",
    "        \n",
    "        print(f\"   Loading Depth-Anything-V2 model: {model_name} on {device}...\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize the depth estimation pipeline\n",
    "            self.pipe = pipeline(\n",
    "                task=\"depth-estimation\",\n",
    "                model=model_name,\n",
    "                device=0 if device == \"cuda\" else -1,\n",
    "                torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "            )\n",
    "            print(f\"   Model loaded successfully: {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _calculate_quality_score(self, depth_map):\n",
    "        \"\"\"Calculate depth map quality score based on statistical measures.\"\"\"\n",
    "        try:\n",
    "            # Normalize depth map\n",
    "            depth_norm = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min() + 1e-8)\n",
    "            \n",
    "            # Calculate various quality metrics\n",
    "            std_score = np.std(depth_norm)  # Higher std indicates more depth variation\n",
    "            gradient_score = np.mean(np.abs(np.gradient(depth_norm)))  # Edge information\n",
    "            \n",
    "            # Combine metrics (weighted average)\n",
    "            quality_score = 0.6 * std_score + 0.4 * gradient_score\n",
    "            \n",
    "            # Clamp to [0, 1] range\n",
    "            return min(1.0, max(0.0, quality_score))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Quality calculation failed: {e}\")\n",
    "            return 0.5  # Default moderate quality\n",
    "\n",
    "    def extract_depth(self, image_path, store_result=True):\n",
    "        \"\"\"Extract depth map from an image with error handling.\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Load and validate image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Validate image quality first\n",
    "            quality_check = validate_image_quality(str(image_path))\n",
    "            if not quality_check['is_valid']:\n",
    "                raise ValueError(f\"Image quality validation failed: {quality_check['issues']}\")\n",
    "            \n",
    "            # Extract depth using pipeline\n",
    "            with torch.no_grad():\n",
    "                result = self.pipe(image)\n",
    "                depth_map = np.array(result['depth'])\n",
    "            \n",
    "            # Calculate processing time\n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Calculate quality score\n",
    "            quality_score = self._calculate_quality_score(depth_map)\n",
    "            \n",
    "            # Store result if requested\n",
    "            if store_result and self.storage_path:\n",
    "                self.storage_path.mkdir(parents=True, exist_ok=True)\n",
    "                save_path = self.storage_path / f\"{Path(image_path).stem}_depth.npy\"\n",
    "                np.save(save_path, depth_map)\n",
    "            \n",
    "            return DepthResult(\n",
    "                depth_map=depth_map,\n",
    "                depth_quality_score=quality_score,\n",
    "                processing_time=processing_time,\n",
    "                model_used=self.model_name\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log individual image failure but don't stop batch processing\n",
    "            logger.error(f\"Failed to process {image_path}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up model resources.\"\"\"\n",
    "        if self.pipe is not None:\n",
    "            del self.pipe\n",
    "            self.pipe = None\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize depth extractor with error handling and GPU fallback\n",
    "print(\"üß† Initializing Depth-Anything-V2 depth extractor...\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüì¶ Initializing Depth-Anything-V2 with:\")\n",
    "    print(f\"   Model: {selected_model}\")\n",
    "    print(f\"   Device: {device}\")\n",
    "    print(f\"   Storage path: {DEPTH_OUTPUT_PATH}\")\n",
    "\n",
    "    # Initialize depth extractor\n",
    "    depth_extractor = DepthAnythingV2Extractor(\n",
    "        model_name=selected_model,\n",
    "        device=device,\n",
    "        storage_path=str(DEPTH_OUTPUT_PATH)\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Depth-Anything-V2 extractor initialized successfully!\")\n",
    "    print(f\"   Ready for batch processing\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize Depth-Anything-V2 extractor: {e}\")\n",
    "\n",
    "    # GPU fallback mechanism\n",
    "    if device == \"cuda\":\n",
    "        print(\"\\nüîÑ Attempting fallback to CPU...\")\n",
    "        try:\n",
    "            depth_extractor = DepthAnythingV2Extractor(\n",
    "                model_name=\"depth-anything/Depth-Anything-V2-Small\",\n",
    "                device=\"cpu\",\n",
    "                storage_path=str(DEPTH_OUTPUT_PATH)\n",
    "            )\n",
    "            print(\"‚úÖ Fallback to CPU successful!\")\n",
    "            DEVICE_CONFIG['device'] = 'cpu'\n",
    "            DEVICE_CONFIG['selected_model'] = 'depth-anything/Depth-Anything-V2-Small'\n",
    "        except Exception as fallback_error:\n",
    "            print(f\"‚ùå CPU fallback also failed: {fallback_error}\")\n",
    "            raise\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3h12K9ugY6l"
   },
   "source": [
    "## 4. Batch Depth Extraction Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxloY2bpgY6l"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"üîÑ Starting batch depth extraction processing...\")\n",
    "\n",
    "# Get list of images to process\n",
    "images_to_process = PROCESSING_BATCH.get('processed_images', [])\n",
    "total_images = len(images_to_process)\n",
    "\n",
    "if total_images == 0:\n",
    "    print(\"‚ùå No images found to process. Please run previous notebooks first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"\\nüìä Processing Configuration:\")\n",
    "print(f\"   Total images: {total_images}\")\n",
    "print(f\"   Quality threshold: {quality_threshold}\")\n",
    "print(f\"   Model: {selected_model}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Calculate optimal batch size for memory management\n",
    "if device == \"cuda\":\n",
    "    # Estimate memory per image (conservative estimate)\n",
    "    estimated_memory_per_image = 0.5  # GB\n",
    "    optimal_batch_size = get_optimal_batch_size(\n",
    "        available_memory=gpu_memory * 0.8,  # Use 80% of available memory\n",
    "        item_size=estimated_memory_per_image\n",
    "    )\n",
    "else:\n",
    "    optimal_batch_size = 1  # Process one at a time on CPU\n",
    "\n",
    "print(f\"   Optimal batch size: {optimal_batch_size}\")\n",
    "\n",
    "# Initialize tracking variables\n",
    "successful_results = []\n",
    "failed_results = []\n",
    "processing_times = []\n",
    "quality_scores = []\n",
    "error_counts = defaultdict(int)\n",
    "\n",
    "print(f\"\\nüöÄ Starting depth extraction...\")\n",
    "print(f\"   Progress will be shown below\")\n",
    "\n",
    "# Process images with progress tracking and error handling\n",
    "with create_progress_bar(total_images, \"Extracting depth maps\") as pbar:\n",
    "    for i, image_info in enumerate(images_to_process):\n",
    "        try:\n",
    "            image_path = image_info.get('path') or image_info.get('file_path')\n",
    "            if not image_path:\n",
    "                raise ValueError(\"No image path found in batch data\")\n",
    "            \n",
    "            # Convert to Path object if string\n",
    "            if isinstance(image_path, str):\n",
    "                image_path = Path(image_path)\n",
    "            \n",
    "            # Check if image exists\n",
    "            if not image_path.exists():\n",
    "                raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "            \n",
    "            # Extract depth with retry logic\n",
    "            def extract_with_retry():\n",
    "                return depth_extractor.extract_depth(image_path, store_result=True)\n",
    "            \n",
    "            result = retry_with_backoff(\n",
    "                func=extract_with_retry,\n",
    "                max_retries=3,\n",
    "                backoff_factor=2.0\n",
    "            )\n",
    "            \n",
    "            # Track successful result\n",
    "            successful_results.append({\n",
    "                'image_path': str(image_path),\n",
    "                'depth_quality_score': result.depth_quality_score,\n",
    "                'processing_time': result.processing_time,\n",
    "                'model_used': result.model_used,\n",
    "                'depth_shape': result.depth_map.shape\n",
    "            })\n",
    "            \n",
    "            processing_times.append(result.processing_time)\n",
    "            quality_scores.append(result.depth_quality_score)\n",
    "            \n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            # Handle GPU memory errors with fallback\n",
    "            error_msg = f\"GPU memory error for {image_path}: {e}\"\n",
    "            logger.error(error_msg)\n",
    "            \n",
    "            try:\n",
    "                # Try CPU fallback for this image\n",
    "                result = handle_gpu_memory_error(\n",
    "                    operation=\"depth_extraction\",\n",
    "                    fallback_func=lambda: depth_extractor.extract_depth(image_path, store_result=True)\n",
    "                )\n",
    "                \n",
    "                successful_results.append({\n",
    "                    'image_path': str(image_path),\n",
    "                    'depth_quality_score': result.depth_quality_score,\n",
    "                    'processing_time': result.processing_time,\n",
    "                    'model_used': result.model_used + \" (CPU fallback)\",\n",
    "                    'depth_shape': result.depth_map.shape\n",
    "                })\n",
    "                \n",
    "            except Exception as fallback_error:\n",
    "                failed_results.append({\n",
    "                    'image_path': str(image_path),\n",
    "                    'error': str(fallback_error),\n",
    "                    'error_type': 'gpu_memory_fallback_failed'\n",
    "                })\n",
    "                error_counts['gpu_memory_fallback_failed'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle other errors - log and continue\n",
    "            error_type = type(e).__name__\n",
    "            error_msg = f\"Failed to process {image_path}: {e}\"\n",
    "            logger.error(error_msg)\n",
    "            \n",
    "            failed_results.append({\n",
    "                'image_path': str(image_path),\n",
    "                'error': str(e),\n",
    "                'error_type': error_type\n",
    "            })\n",
    "            error_counts[error_type] += 1\n",
    "        \n",
    "        # Update progress\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Memory cleanup every 10 images\n",
    "        if (i + 1) % 10 == 0:\n",
    "            cleanup_variables(['result'])\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "# Calculate statistics\n",
    "successful_extractions = len(successful_results)\n",
    "failed_extractions = len(failed_results)\n",
    "success_rate = (successful_extractions / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "# Quality threshold analysis\n",
    "above_threshold = sum(1 for score in quality_scores if score >= quality_threshold)\n",
    "below_threshold = len(quality_scores) - above_threshold\n",
    "\n",
    "print(f\"\\n‚úÖ Batch depth extraction completed!\")\n",
    "print(f\"\\nüìä Processing Results:\")\n",
    "print(f\"   Total images processed: {total_images}\")\n",
    "print(f\"   Successful extractions: {successful_extractions}\")\n",
    "print(f\"   Failed extractions: {failed_extractions}\")\n",
    "print(f\"   Low quality (below threshold): {below_threshold}\")\n",
    "print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "\n",
    "if processing_times:\n",
    "    print(f\"\\n‚è±Ô∏è  Processing Performance:\")\n",
    "    print(f\"   Average time per image: {np.mean(processing_times):.2f} seconds\")\n",
    "    print(f\"   Total processing time: {sum(processing_times):.1f} seconds\")\n",
    "    print(f\"   Fastest: {min(processing_times):.2f}s, Slowest: {max(processing_times):.2f}s\")\n",
    "\n",
    "if error_counts:\n",
    "    print(f\"\\n‚ùå Error Summary:\")\n",
    "    for error_type, count in error_counts.items():\n",
    "        print(f\"   {error_type}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results_header"
   },
   "source": [
    "## 5. Save Results and Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results_cell"
   },
   "outputs": [],
   "source": [
    "print(\"üíæ Saving depth extraction results and generating reports...\")\n",
    "\n",
    "# Prepare comprehensive results\n",
    "depth_extraction_results = {\n",
    "    'stage_info': {\n",
    "        'stage_name': 'depth_anything_v2_extraction',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_used': selected_model,\n",
    "        'device_used': device,\n",
    "        'total_processing_time': sum(processing_times) if processing_times else 0\n",
    "    },\n",
    "    'processing_statistics': {\n",
    "        'total_images': total_images,\n",
    "        'successful_extractions': successful_extractions,\n",
    "        'failed_extractions': failed_extractions,\n",
    "        'success_rate': success_rate,\n",
    "        'above_quality_threshold': above_threshold,\n",
    "        'below_quality_threshold': below_threshold\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'mean_processing_time': np.mean(processing_times) if processing_times else 0,\n",
    "        'std_processing_time': np.std(processing_times) if processing_times else 0,\n",
    "        'min_processing_time': min(processing_times) if processing_times else 0,\n",
    "        'max_processing_time': max(processing_times) if processing_times else 0,\n",
    "        'mean_quality_score': np.mean(quality_scores) if quality_scores else 0,\n",
    "        'std_quality_score': np.std(quality_scores) if quality_scores else 0\n",
    "    },\n",
    "    'successful_results': successful_results,\n",
    "    'failed_results': failed_results,\n",
    "    'error_summary': dict(error_counts),\n",
    "    'configuration': {\n",
    "        'quality_threshold': quality_threshold,\n",
    "        'batch_size': optimal_batch_size,\n",
    "        'device_config': DEVICE_CONFIG\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results using shared utility\n",
    "try:\n",
    "    save_stage_results(\n",
    "        data=depth_extraction_results,\n",
    "        stage_name=\"depth_anything_v2_extraction\",\n",
    "        metadata={\n",
    "            'model_used': selected_model,\n",
    "            'processing_time': sum(processing_times) if processing_times else 0,\n",
    "            'success_rate': success_rate\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Results saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Failed to save results: {e}\")\n",
    "    # Continue execution even if saving fails\n",
    "\n",
    "# Generate quality report\n",
    "quality_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_depth_maps': successful_extractions,\n",
    "    'quality_threshold': quality_threshold,\n",
    "    'quality_distribution': {\n",
    "        'above_threshold': above_threshold,\n",
    "        'below_threshold': below_threshold,\n",
    "        'percentage_above': (above_threshold / successful_extractions * 100) if successful_extractions > 0 else 0\n",
    "    },\n",
    "    'quality_statistics': {\n",
    "        'mean': np.mean(quality_scores) if quality_scores else 0,\n",
    "        'median': np.median(quality_scores) if quality_scores else 0,\n",
    "        'std': np.std(quality_scores) if quality_scores else 0,\n",
    "        'min': min(quality_scores) if quality_scores else 0,\n",
    "        'max': max(quality_scores) if quality_scores else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Quality Report Summary:\")\n",
    "print(f\"   Total depth maps generated: {successful_extractions}\")\n",
    "print(f\"   Above quality threshold ({quality_threshold}): {above_threshold} ({quality_report['quality_distribution']['percentage_above']:.1f}%)\")\n",
    "print(f\"   Mean quality score: {quality_report['quality_statistics']['mean']:.3f}\")\n",
    "print(f\"   Quality score range: {quality_report['quality_statistics']['min']:.3f} - {quality_report['quality_statistics']['max']:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Depth extraction stage completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}